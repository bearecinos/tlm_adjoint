\documentclass[11pt]{article}
\usepackage[a4paper,margin=2cm,left=1cm,right=1cm]{geometry}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{color}
\usepackage[colorlinks,citecolor=blue,linkcolor=blue,urlcolor=blue]{hyperref}
\usepackage{natbib}

\pretolerance=10000

\definecolor{grey}{rgb}{0.7,0.7,0.7}
\usepackage{listings}
\lstset{
  aboveskip=5.5pt,
  basicstyle=\ttfamily\footnotesize,
  belowskip=0cm,
  firstnumber=1,
  keywordstyle=\color{blue},
  language=Python,
  numbers=left,
  numberstyle=\color{grey},
  showstringspaces=false,
  stepnumber=5,
  stringstyle=\color{red},
  xleftmargin=1.5cm
}

\usepackage[compact]{titlesec}
\setlength{\parindent}{0cm}
\setlength{\parskip}{5.5pt}

\title{\texttt{tlm\_adjoint} manual}

\begin{document}

\maketitle

\tableofcontents

\section{Introduction}

\texttt{tlm\_adjoint} \citep{maddison2019} is a Python library for high-level
algorithmic differentiation, principally for models written using FEniCS
\citep{logg2012,alnaes2015} or Firedrake \citep{rathgeber2016}.
\texttt{tlm\_adjoint} follows the high-level algorithmic differentiation
methodology described in \citet{farrell2013}, and generalizes these for higher
order tangent-linear and adjoint calculations. \texttt{tlm\_adjoint} further
allows for automated assembly and solver caching \citep[see][]{maddison2014},
and allows for the introduction of custom equations.

\section{Installation}

For installation information see the \texttt{README} file in the
\texttt{tlm\_adjoint} root directory.

\section{A simple example}\label{sect:diffusion}

Consider the diffusion equation, discretized with a continuous Galerkin finite
element discretization in space and with a backward Euler discretization in
time, subject to homogeneous Dirichlet boundary conditions,
\begin{equation*}
  \int_\Omega \zeta \frac{\psi^{n + 1} - \psi^n}{\Delta t}
    = -\int_\Omega \nabla \zeta \cdot \kappa \nabla \psi^{n + 1}
    \quad \forall \zeta \in V \quad \forall n = 0, 1, 2, \ldots,
\end{equation*}
where the discrete solution at time $t = n \Delta t$ is $\psi^n \in V$, $V$ is
some appropriate subspace of $H^1_0 \left( \Omega; \mathbb{R} \right)$, and
where $\Omega$ is some appropriate subset of $\mathbb{R}^d$ in $d$-dimensions.
Here $\kappa$ is a positive real constant, and $\psi^0 \in V$ is a discrete
initial condition.

\subsection{Forward}

A basic implementation in Firedrake takes the form
\begin{lstlisting}
from firedrake import *

mesh = UnitSquareMesh(100, 100)
X = SpatialCoordinate(mesh)
space = FunctionSpace(mesh, "Lagrange", 1)
test, trial = TestFunction(space), TrialFunction(space)

psi_n = Function(space, name="psi_n")
psi_n.interpolate(
    exp(X[0] * X[1]) * sin(2.0 * pi * X[0]) * sin(5.0 * pi * X[1])
    + sin(pi * X[0]) * sin(2.0 * pi * X[1]))

psi_np1 = Function(space, name="psi_np1")

kappa = Constant(0.001)
dt = Constant(0.2)
bc = DirichletBC(space, 0.0, "on_boundary")
N = 100

solver = LinearVariationalSolver(
    LinearVariationalProblem(inner(trial / dt, test) * dx
                             + inner(kappa * grad(trial), grad(test)) * dx,
                             inner(psi_n / dt, test) * dx,
                             psi_np1, bc),
    solver_parameters={"ksp_type": "preonly",
                       "pc_type": "lu"})

psi_n_file = File("psi.pvd")
psi_n_file.write(psi_n, time=0.0)

for n in range(N):
    solver.solve()
    psi_n.assign(psi_np1)

    psi_n_file.write(psi_n, time=(n + 1) * float(dt))
\end{lstlisting}

\subsection{First order adjoint}

Define the functional
\begin{equation*}
  J \left( \psi^N \right) = \int_\Omega \left( \psi^N - 1 \right) \left( \psi^N - 1 \right).
\end{equation*}
A forward model constrained derivative of $J$ with respect to the discrete
initial condition $\psi^0$ can computed via
\begin{lstlisting}
from firedrake import *
from tlm_adjoint.firedrake import *
stop_manager()

N = 100
configure_checkpointing("multistage", {"blocks": N, "snaps_in_ram": 5})

mesh = UnitSquareMesh(100, 100)
X = SpatialCoordinate(mesh)
space = FunctionSpace(mesh, "Lagrange", 1)
test, trial = TestFunction(space), TrialFunction(space)

psi_0 = Function(space, name="psi_0", static=True)
psi_0.interpolate(
    exp(X[0] * X[1]) * sin(2.0 * pi * X[0]) * sin(5.0 * pi * X[1])
    + sin(pi * X[0]) * sin(2.0 * pi * X[1]))

kappa = Constant(0.001, static=True)
dt = Constant(0.2, static=True)
bc = HomogeneousDirichletBC(space, "on_boundary")


def forward(psi_0, psi_n_file=None):
    clear_caches()

    psi_n = Function(space, name="psi_n")
    psi_np1 = Function(space, name="psi_np1")

    class InteriorAssignment(Equation):
        def __init__(self, x, y):
            super().__init__(x, [x, y], nl_deps=[], ic=False, adj_ic=False)
            self._bc = DirichletBC(function_space(x), 0.0, "on_boundary")

        def forward_solve(self, x, deps=None):
            _, y = self.dependencies() if deps is None else deps
            function_assign(x, y)
            self._bc.apply(x)

        def adjoint_derivative_action(self, nl_deps, dep_index, adj_x):
            if dep_index == 0:
                return adj_x
            elif dep_index == 1:
                b = function_copy(adj_x)
                self._bc.apply(b)
                return (-1.0, b)
            else:
                raise IndexError("dep_index out of bounds")

        def adjoint_jacobian_solve(self, adj_x, nl_deps, b):
            return b

        def tangent_linear(self, M, dM, tlm_map):
            x, y = self.dependencies()
            tlm_y = get_tangent_linear(y, M, dM, tlm_map)
            if tlm_y is None:
                return ZeroAssignment(tlm_map[x])
            else:
                return InteriorAssignment(tlm_map[x], tlm_y)

    InteriorAssignment(psi_n, psi_0).solve()

    eq = EquationSolver(
        inner(trial / dt, test) * dx
        + inner(kappa * grad(trial), grad(test)) * dx
        == inner(psi_n / dt, test) * dx,
        psi_np1, bc,
        solver_parameters={"ksp_type": "preonly",
                           "pc_type": "lu"})
    cycle = Assignment(psi_n, psi_np1)

    if psi_n_file is not None:
        psi_n_file.write(psi_n, time=0.0)

    for n in range(N):
        eq.solve()
        cycle.solve()

        if psi_n_file is not None:
            psi_n_file.write(psi_n, time=(n + 1) * float(dt))
        if n < N - 1:
            new_block()

    J = Functional(name="J")
    J.assign(dot(psi_n - Constant(1.0), psi_n - Constant(1.0)) * dx)
    return J


start_manager()
J = forward(psi_0, psi_n_file=File("psi.pvd"))
stop_manager()

dJ = compute_gradient(J, psi_0)
\end{lstlisting}

The key changes which appear here are
\begin{itemize}
  \item \texttt{import tlm\_adjoint.firedrake}, to use the
    \texttt{tlm\_adjoint} library. For further details see section
    \ref{sect:backends}.
  \item \texttt{start\_manager} and \texttt{stop\_manager}, which enable and
    disable the underlying \texttt{EquationManager}. For further details see
    section \ref{sect:EquationManager_state}.
  \item The instantiation of \texttt{Assignment} and \texttt{EquationSolver}
    objects. For further details see section \ref{sect:Equation}.
  \item The use of a subclass of \texttt{Equation} to define a custom equation.
    For further details see section \ref{sect:custom}.
  \item The \texttt{static} keyword when initialising certain \texttt{Constant}
    and \texttt{Function} objects, and the instantiation of a
    \texttt{HomogeneousDirichletBC} object. For further details see sections
    \ref{sect:EquationSolver_caching} and \ref{sect:flags}.
  \item The use of the \texttt{clear\_caches} function. For further details see
    section \ref{sect:clear_caches}.
  \item The definition of the functional. For further details see section
    \ref{sect:Functional}.
  \item The use of a \texttt{forward} function mapping from the control (here
    $\psi^0$) to the functional. This facilitates verification (section
    \ref{sect:verification}), the evaluation of forward model constrained
    Hessian actions (section \ref{sect:Hessian}), and the solution of
    optimization problems (section \ref{sect:minimization}).
  \item The use of the \texttt{configure\_checkpointing} and
    \texttt{new\_block} functions to control checkpointing. For further details
    see section \ref{sect:checkpointing}. Here the binomial checkpointing
    method of \citet{griewank2000} is used, with $5$ checkpoints stored in
    memory. 
  \item The calculation of the forward model constrained derivative using the
    \texttt{compute\_gradient} function. For further details see section
    \ref{sect:first_order_adjoint}.
\end{itemize}

\subsection{Second order adjoint}

The action of the forward model constrained Hessian on a $\zeta \in V$, where
the Hessian is defined by the forward model constrained (second) derivative of
the functional $J$ with respect to the initial condition $\psi^0$, can be
computed via
\begin{lstlisting}
from firedrake import *
from tlm_adjoint.firedrake import *
stop_manager()

N = 100
configure_checkpointing("multistage", {"blocks": N, "snaps_in_ram": 5})

mesh = UnitSquareMesh(100, 100)
X = SpatialCoordinate(mesh)
space = FunctionSpace(mesh, "Lagrange", 1)
test, trial = TestFunction(space), TrialFunction(space)

psi_0 = Function(space, name="psi_0", static=True)
psi_0.interpolate(
    exp(X[0] * X[1]) * sin(2.0 * pi * X[0]) * sin(5.0 * pi * X[1])
    + sin(pi * X[0]) * sin(2.0 * pi * X[1]))

kappa = Constant(0.001, static=True)
dt = Constant(0.2, static=True)
bc = HomogeneousDirichletBC(space, "on_boundary")


def forward(psi_0, psi_n_file=None):
    clear_caches()

    psi_n = Function(space, name="psi_n")
    psi_np1 = Function(space, name="psi_np1")

    class InteriorAssignment(Equation):
        def __init__(self, x, y):
            super().__init__(x, [x, y], nl_deps=[], ic=False, adj_ic=False)
            self._bc = DirichletBC(function_space(x), 0.0, "on_boundary")

        def forward_solve(self, x, deps=None):
            _, y = self.dependencies() if deps is None else deps
            function_assign(x, y)
            self._bc.apply(x)

        def adjoint_derivative_action(self, nl_deps, dep_index, adj_x):
            if dep_index == 0:
                return adj_x
            elif dep_index == 1:
                b = function_copy(adj_x)
                self._bc.apply(b)
                return (-1.0, b)
            else:
                raise IndexError("dep_index out of bounds")

        def adjoint_jacobian_solve(self, adj_x, nl_deps, b):
            return b

        def tangent_linear(self, M, dM, tlm_map):
            x, y = self.dependencies()
            tlm_y = get_tangent_linear(y, M, dM, tlm_map)
            if tlm_y is None:
                return ZeroAssignment(tlm_map[x])
            else:
                return InteriorAssignment(tlm_map[x], tlm_y)

    InteriorAssignment(psi_n, psi_0).solve()

    eq = EquationSolver(
        inner(trial / dt, test) * dx
        + inner(kappa * grad(trial), grad(test)) * dx
        == inner(psi_n / dt, test) * dx,
        psi_np1, bc,
        solver_parameters={"ksp_type": "preonly",
                           "pc_type": "lu"})
    cycle = Assignment(psi_n, psi_np1)

    if psi_n_file is not None:
        psi_n_file.write(psi_n, time=0.0)

    for n in range(N):
        eq.solve()
        cycle.solve()

        if psi_n_file is not None:
            psi_n_file.write(psi_n, time=(n + 1) * float(dt))
        if n < N - 1:
            new_block()

    J = Functional(name="J")
    J.assign(dot(psi_n - Constant(1.0), psi_n - Constant(1.0)) * dx)
    return J


zeta = Function(space, name="zeta", static=True)
zeta.interpolate(sin(pi * X[0]) * sin(pi * X[1]))
configure_tlm((psi_0, zeta))

start_manager()
J = forward(psi_0, psi_n_file=File("psi.pvd"))
stop_manager()

ddJ = compute_gradient(J.tlm_functional((psi_0, zeta)), psi_0)
\end{lstlisting}

The key changes which appear here are
\begin{itemize}
  \item The use of the \texttt{configure\_tlm} function, to enable the
    derivation and solution of tangent-linear equations. 
  \item The use of the \texttt{tlm\_functional} method of the
    \texttt{Functional} object when performing the derivative calculation.
\end{itemize}
For further details see section \ref{sect:higher_order}.

\section{Backends}\label{sect:backends}

The FEniCS backend may be used via, e.g.
\begin{lstlisting}
from fenics import *
from tlm_adjoint.fenics import *
\end{lstlisting}

The Firedrake backend may be used via, e.g.
\begin{lstlisting}
from firedrake import *
from tlm_adjoint.firedrake import *
\end{lstlisting}

The NumPy backend may be used via, e.g.
\begin{lstlisting}
import numpy as np
from tlm_adjoint.numpy import *
\end{lstlisting}

\section{Automatic processing}\label{sect:overrides}

\texttt{tlm\_adjoint} has the ability to compute derivative information
associated with some models written using FEniCS or Firedrake with minimal
modification, through automatic processing of encountered calculations.
Consider for example the very basic model
\begin{lstlisting}
from firedrake import *

mesh = UnitIntervalMesh(10)
X = SpatialCoordinate(mesh)
space = FunctionSpace(mesh, "Lagrange", 1)
test, trial = TestFunction(space), TrialFunction(space)

F = Function(space, name="F")
G = Function(space, name="G")

F.interpolate(sin(pi * X[0]))
solve(inner(trial, test) * dx == inner(F * F, test) * dx,
      G, solver_parameters={"ksp_type": "preonly",
                            "pc_type": "lu"})

J = assemble(inner(G, G) * dx)

info(f"G L^2 norm = {sqrt(J):.16e}")
\end{lstlisting}
This model contains the key line
\begin{lstlisting}
solve(inner(trial, test) * dx == inner(F * F, test) * dx,
      G, solver_parameters={"ksp_type": "preonly",
                            "pc_type": "lu"})
\end{lstlisting}

A forward model constrained derivative can be computed via, for example
\begin{lstlisting}
from firedrake import *
from tlm_adjoint.firedrake import *

mesh = UnitIntervalMesh(10)
X = SpatialCoordinate(mesh)
space = FunctionSpace(mesh, "Lagrange", 1)
test, trial = TestFunction(space), TrialFunction(space)

F = Function(space, name="F")
G = Function(space, name="G")

F.interpolate(sin(pi * X[0]), annotate=False, tlm=False)
solve(inner(trial, test) * dx == inner(F * F, test) * dx,
      G, solver_parameters={"ksp_type": "preonly",
                            "pc_type": "lu"})

J = Functional(name="J")
J.assign(inner(G, G) * dx)

info(f"G L^2 norm = {sqrt(J.value()):.16e}")

dJ = compute_gradient(J, F)
\end{lstlisting}
Note that the use of the \texttt{solve} function is unchanged. Internally
\texttt{tlm\_adjoint} overrides the \texttt{solve} function and processes the
equation being solved.

\texttt{tlm\_adjoint} intercepts or overrides a small number of functions,
classes, and methods in this way, but this is limited to
\begin{itemize}
  \item \texttt{assemble}
  \item (FEniCS only) \texttt{assemble\_system}
  \item \texttt{solve}
  \item \texttt{project}
  \item (FEniCS only) \texttt{DirichletBC.apply}
  \item \texttt{Constant.assign}
  \item \texttt{Function.assign}
  \item (Firedrake only) \texttt{Function.project}
  \item \texttt{Function.vector}
  \item (FEniCS only) Multiplication by assembled matrices
  \item (FEniCS only) \texttt{LUSolver} and \texttt{KrylovSolver}
  \item (Firedrake only) \texttt{LinearSolver}
  \item \texttt{LinearVariationalSolver}
  \item \texttt{NonlinearVariationalSolver}
  \item (Firedrake only) \texttt{interpolate}, \texttt{Function.interpolate},
    and \texttt{Interpolator.interpolate}
\end{itemize}

Note that the full functionality of intercepted or overridden functions,
classes, or methods may not be supported by \texttt{tlm\_adjoint}. The use of
this approach may also be inefficient -- see section
\ref{sect:Equation_rationale} -- and it is instead recommended that appropriate
\texttt{Equation} objects are used directly.

\section{\texttt{Equation} objects}\label{sect:Equation}

\subsection{Rationale}\label{sect:Equation_rationale}

\texttt{tlm\_adjoint} constructs a representation of a forward model in terms
of \texttt{Equation} objects. When intercepting or overriding FEniCS or
Firedrake functionality (see section \ref{sect:overrides})
\texttt{tlm\_adjoint} builds the required \texttt{Equation} objects
automatically. However this can potentially lead to the construction of a large
number of independent \texttt{Equation} objects, even if the same equations are
solved repeatedly. Instead, one can explicitly instantiate \texttt{Equation}
objects, and then solve the same equation multiple times by calling its
\texttt{solve} method. This can facilitate caching and improve performance.

\subsection{Solving equations}

An equation, defined by an \texttt{Equation} object, is solved by calling its
\texttt{solve} method, for example
\begin{lstlisting}
eq = EquationSolver(inner(trial, test) * dx == inner(F * F, test) * dx,
                    G, solver_parameters={"ksp_type": "preonly",
                                          "pc_type": "lu"})
eq.solve()
\end{lstlisting}

\subsection{``Functions''}

\texttt{tlm\_adjoint} interfaces with backend datatypes, termed ``functions'',
by providing a generic interface which can be used to extract or update
``function'' data. With the FEniCS and Firedrake backends \texttt{Constant} and
\texttt{Function} objects are interfaced, and these can appear as the solution
or a dependency of an \texttt{Equation}.

\subsection{Built-in \texttt{Equation} classes: All backends}

\subsubsection{\texttt{ZeroAssignment}}

A \texttt{ZeroAssignment} represents the trivial equation
\begin{equation*}
  x = 0.
\end{equation*}
A \texttt{ZeroAssignment} can be instantiated via
\begin{lstlisting}
eq = ZeroAssignment(x)
\end{lstlisting}
where \texttt{x} is the function being solved for, or
\begin{lstlisting}
eq = ZeroAssignment(X)
\end{lstlisting}
where \texttt{X} is a sequence of functions being solved for.

The intended use of a \texttt{ZeroAssignment} is in the definition of
\texttt{tangent\_linear} methods of \texttt{Equation} classes (see section
\ref{sect:tangent_linear}).

\subsubsection{\texttt{Assignment}}

An \texttt{Assignment} represents an assignment
\begin{equation*}
  x = y.
\end{equation*}
An \texttt{Assignment} can be instantiated via
\begin{lstlisting}
eq = Assignment(x, y)
\end{lstlisting}
where \texttt{x} is the function being solved for.

\subsubsection{\texttt{Axpy}}

An \texttt{Axpy} represents the equation
\begin{equation*}
  z = y + \alpha x,
\end{equation*}
where $\alpha$ is a scalar constant. An \texttt{Axpy} can be instantiated
via
\begin{lstlisting}
eq = Axpy(z, y, alpha, x)
\end{lstlisting}
where \texttt{z} is the function being solved for.

\subsubsection{\texttt{LinearCombination}}

A \texttt{LinearCombination} represents the equation
\begin{equation*}
  x = \sum_{i = 1}^N \alpha_i y_i,
\end{equation*}
where the $\alpha_i$ are scalar constants. A \texttt{LinearCombination} is
instantiated via
\begin{lstlisting}
eq = LinearCombination(x, (alpha_1, y_1), (alpha_2, y_2), [...])
\end{lstlisting}
where \texttt{x} is the function being solved for, and where an arbitrary
number of tuples may be supplied as further arguments.

\subsubsection{\texttt{FixedPointSolver}}

The \texttt{FixedPointSolver} class implements the adjoint fixed-point
iteration approach described in \citet{christianson1994}, and its
tangent-linear analogue \citep{gilbert1992}. The \texttt{FixedPointSolver}
constructor has the form
\begin{lstlisting}
def __init__(self, eqs, solver_parameters):
\end{lstlisting}
with constructor arguments
\begin{itemize}
  \item \texttt{eqs}, a sequence of \texttt{Equation} objects. A function
    cannot appear as the solution to two or more equations.
  \item \texttt{solver\_parameters}, a dictionary, solver parameters (described
    below).
\end{itemize}
Keys for the \texttt{solver\_parameters} argument are based on the
\texttt{KrylovSolver} parameters in FEniCS 2017.2.0, and are
\begin{itemize}
  \item \texttt{absolute\_tolerance}, a float, absolute tolerance for the
    solution change $2$-norm (required).
  \item \texttt{relative\_tolerance}, a float, relative tolerance for the
    solution change $2$-norm (required).
  \item \texttt{maximum\_iterations}, a positive integer, maximum permitted
    iterations (default $1000$).
  \item \texttt{nonzero\_initial\_guess}, a logical, whether to use a non-zero
    initial guess (default true).
  \item \texttt{adjoint\_nonzero\_initial\_guess}, a logical, whether to use a
    non-zero initial guess for an adjoint solve (default true).
\end{itemize}

\subsection{Built-in \texttt{Equation} classes: FEniCS and Firedrake}

\subsubsection{\texttt{EquationSolver}}\label{sect:EquationSolver}

The \texttt{EquationSolver} class defines a finite element discretized partial
differential equation. The \texttt{EquationSolver} constructor has the form
\begin{lstlisting}
def __init__(self, eq, x, bcs=None, J=None, form_compiler_parameters=None,
             solver_parameters=None, adjoint_solver_parameters=None,
             tlm_solver_parameters=None, cache_jacobian=None,
             cache_adjoint_jacobian=None, cache_tlm_jacobian=None,
             cache_rhs_assembly=None, match_quadrature=None,
             defer_adjoint_assembly=None):
\end{lstlisting}
with constructor arguments
\begin{itemize}
  \item \texttt{eq}, a \texttt{ufl.classes.Equation}, defining the finite
    element discretized partial differential equation. As for the FEniCS
    \texttt{solve} function the equation must be linear if \texttt{eq} is of
    the form ``bilinear form equals linear form'', and is assumed non-linear if
    \texttt{eq} is of the form ``linear form equals zero''.
  \item \texttt{x}, a \texttt{Function}, the solution to the equation.
  \item \texttt{bcs}, a Dirichlet boundary condition, or a sequence of
    Dirichlet boundary conditions.
  \item \texttt{J}, a \texttt{ufl.classes.Form}, defining the Jacobian to be
    used in the solution of a non-linear forward equation. Used only if the
    forward equation is assumed non-linear.
  \item \texttt{form\_compiler\_parameters}, a dictionary of parameters passed
    to the form compiler.
  \item \texttt{solver\_parameters}, a dictionary of solver parameters.
  \item \texttt{adjoint\_solver\_parameters}, a dictionary of solver parameters
    used to solve an associated adjoint equation. Adjoint solver parameters are
    derived from \texttt{solver\_parameters} if this is not supplied.
  \item \texttt{tlm\_solver\_parameters}, a dictionary of solver parameters
    used to solve associated tangent-linear equations. Linear solver parameters
    as defined by \texttt{solver\_parameters} are used if this is not supplied.
  \item \texttt{cache\_jacobian}, whether to cache the Jacobian matrix and
    linear solver used, if the equation is not assumed non-linear, in solving
    the forward equation (see section \ref{sect:EquationSolver_caching}). If
    not supplied and
    \texttt{parameters["tlm\_adjoint"]}\texttt{["EquationSolver"]}\texttt{["enable\_jacobian\_caching"]}
    is true (which is the default) then Jacobian matrix caching is
    autodetected. If not supplied and
    \texttt{parameters["tlm\_adjoint"]}\texttt{["EquationSolver"]}\texttt{["enable\_jacobian\_caching"]}
    is false then Jacobian matrix caching is disabled.
  \item \texttt{cache\_adjoint\_jacobian}, whether to cache the Jacobian matrix
    and linear solver used in the solution of an associated adjoint equation.
    Takes the value of \texttt{cache\_jacobian} if not supplied.
  \item \texttt{cache\_tlm\_jacobian}, whether to cache the Jacobian matrices
    and linear solvers used in the solution of associated tangent-linear
    equations. Takes the value of \texttt{cache\_jacobian} if not supplied.
  \item \texttt{cache\_rhs\_assembly}, whether to enable right-hand-side
    assembly caching in the forward (if the equation is not assumed non-linear)
    or adjoint equations (see section \ref{sect:EquationSolver_caching}).
    Defaults to
    \texttt{parameters["tlm\_adjoint"]}\texttt{["EquationSolver"]}\texttt{["cache\_rhs\_assembly"]},
    which by default is true.
  \item \texttt{match\_quadrature}, whether to use the same quadrature degree
    in all finite element assembly. May be required for discrete consistency if
    incomplete quadrature is used. Defaults to
    \texttt{parameters["tlm\_adjoint"]}\texttt{["EquationSolver"]}\texttt{["match\_quadrature"]},
    which by default is false.
  \item \texttt{defer\_adjoint\_assembly}. If false, assemble adjoint terms as
    soon as they are computed. If true, gather multiple terms from different
    equations prior to assembly. In this latter case default form compiler
    parameters are used for the assembly. Has no effect for adjoint terms for
    which assembly caching is used. Defaults to
    \texttt{parameters["tlm\_adjoint"]}\texttt{["EquationSolver"]}\texttt{["defer\_adjoint\_assembly"]},
    which by default is false.
\end{itemize}
The \texttt{eq}, \texttt{x}, \texttt{bcs}, \texttt{J},
\texttt{form\_compiler\_parameters} and \texttt{solver\_parameters} arguments
are based on the interface for the FEniCS \texttt{solve} function.

Note that the \texttt{EquationSolver} preserves matrix symmetry when strong
Dirichlet boundary conditions are supplied in the solution of forward equations
which are not assumed non-linear, and in the solution of adjoint equations.
Symmetry preservation for forward equations which are assumed non-linear is
determined by the behaviour of the FEniCS or Firedrake \texttt{solve} function.

With the Firedrake backend additional solver parameters may be defined
\begin{itemize}
  \item \texttt{solver\_parameters["tlm\_adjoint"]["options\_prefix"]}, passed
    as the \texttt{options\_prefix} argument to \texttt{LinearSolver}.
  \item \texttt{solver\_parameters["tlm\_adjoint"]["nullspace"]},
    passed as the \texttt{nullspace} argument to \texttt{LinearSolver}. 
  \item \texttt{solver\_parameters["tlm\_adjoint"]["transpose\_nullspace"]},
    passed as the \texttt{transpose\_nullspace} argument to
    \texttt{LinearSolver}. 
  \item \texttt{solver\_parameters["tlm\_adjoint"]["near\_nullspace"]}, passed
    as the \texttt{near\_nullspace} argument to \texttt{LinearSolver}. 
\end{itemize}
If the \texttt{adjoint\_solver\_parameters} argument is not passed to the
\texttt{EquationSolver} constructor then the null space and transpose null
space are swapped in the adjoint solver parameters.

\subsubsection{\texttt{Projection}}

A \texttt{Projection} is a subclass of the \texttt{EquationSolver} class, and
represents either the equation
\begin{equation*}
  \int_\Omega \phi^* \cdot \psi = b \left( \phi^* \right) \quad \forall \phi \in V,
\end{equation*}
where $\psi \in V$ and $b$ is a linear form, or
\begin{equation*}
  \int_\Omega \phi^* \cdot \psi = \int_\Omega \phi^* \cdot \xi \quad \forall \phi \in V,
\end{equation*}
where $\xi$ is a given expression.

The \texttt{Projection} constructor has the form
\begin{lstlisting}
def __init__(self, x, rhs, *args, **kwargs):
\end{lstlisting}
where \texttt{rhs} is a \texttt{ufl.classes.Form} (for the first case above) or
expression (for the second), and \texttt{x} is the \texttt{Function} being
solved for. Remaining constructor arguments are as for the
\texttt{EquationSolver} class.

\subsubsection{\texttt{DirichletBCApplication}}

A \texttt{DirichletBCApplication} represents the application of a strong
Dirichlet boundary condition, represented in the form of an equation
\begin{equation*}
  \tilde{\psi} = P \tilde{\xi},
\end{equation*}
where $\tilde{\psi}$ and $\tilde{\xi}$ are vectors whose elements are the
discrete degrees of freedom for functions $\psi, \xi \in V$, and $P$ is a
$\left( 0, 1 \right)$-matrix. A \texttt{DirichletBCApplication} can be
instantiated via
\begin{lstlisting}
eq = DirichletBCApplication(psi, xi, *args, **kwargs)
\end{lstlisting}
where \texttt{xi} and \texttt{psi} are \texttt{Function} objects corresponding
to $\xi$ and $\psi$ in the equation above. Remaining arguments are passed
directly to the \texttt{DirichletBC} constructor.

\subsubsection{\texttt{Assembly}}\label{sect:Assembly}

An \texttt{Assembly} represents the assembly of a rank zero or rank one form.
The \texttt{Assembly} constructor has the form
\begin{lstlisting}
def __init__(self, x, rhs, *, form_compiler_parameters=None,
             match_quadrature=None):
\end{lstlisting}
with constructor arguments
\begin{itemize}
  \item \texttt{rhs}, a \texttt{ufl.classes.Form}, defining the form.
  \item \texttt{x}, a function, the solution to the equation.
  \item \texttt{form\_compiler\_parameters}, a dictionary of parameters passed
    to the form compiler.
  \item \texttt{match\_quadrature}, whether to use the same quadrature degree
    in all finite element assembly. May be required for discrete consistency if
    incomplete quadrature is used. Defaults to
    \texttt{parameters["tlm\_adjoint"]}\texttt{["Assembly"]}\texttt{["match\_quadrature"]},
    which by default is false.
\end{itemize}

For a rank zero form the solution \texttt{x} must be a scalar, for example as
returned by the \texttt{new\_scalar\_function} function
\begin{lstlisting}
x = new_scalar_function(comm=comm)
\end{lstlisting}
where here the optional argument \texttt{comm} defines the MPI communicator
associated with the function.

\subsection{Built-in \texttt{Equation} classes: FEniCS}

\subsubsection{\texttt{Interpolation}}\label{sect:Interpolation}

An \texttt{Interpolation} represents interpolation of a given scalar-valued
function $\xi \in W$ onto a function space $V$, represented in the form of an
equation
\begin{equation*}
  \tilde{\psi} = P \tilde{\xi},
\end{equation*}
where $\tilde{\psi}$ and $\tilde{\xi}$ are vectors whose elements are the
discrete degrees of freedom for scalar-valued functions $\psi \in V, \xi \in
W$, and $P$ is a matrix. An \texttt{Interpolation} can be instantiated via
\begin{lstlisting}
eq = Interpolation(x, y)
\end{lstlisting}
where \texttt{x} is the \texttt{Function} being solved for, and \texttt{y} the
\texttt{Function} being interpolated. An optional \texttt{x\_coords} argument
may be supplied to define the coordinates associated with the degrees of
freedom for $\tilde{\psi}$. An optional \texttt{tolerance} argument may be
supplied to define the maximum permitted distance of a coordinate from a cell.

In parallel the node-node graph associated with the discrete function space for
\texttt{y} must have no edges between nodes owned by different processes. In
parallel the \texttt{Interpolation} can be combined with the
\texttt{LocalProjection} in order to project functions in more general function
spaces onto an appropriate discontinuous Galerkin function space, prior to
interpolation.

\subsubsection{\texttt{PointInterpolation}}

With the FEniCS backend, a \texttt{PointInterpolation} represents interpolation
of a given scalar-valued function $\xi \in W$ onto a given set of points,
\begin{equation*}
  \tilde{\psi} = P \tilde{\xi},
\end{equation*}
where the elements of $\tilde{\psi}$ are the interpolated values, $\tilde{\xi}$
is a vector whose elements are the discrete degrees of freedom for a
scalar-valued function $\xi \in W$, and where $P$ is a matrix. A
\texttt{PointInterpolation} can be instantiated via
\begin{lstlisting}
eq = PointInterpolation(X, y, X_coords=X_coords)
\end{lstlisting}
where \texttt{X} is a sequence of scalars being solved for (for example each as
returned by the \texttt{new\_scalar\_function} function -- see section
\ref{sect:Assembly}) and \texttt{X\_coords} is a NumPy array defining the
coordinates at which to interpolate the \texttt{Function} \texttt{y}. An
optional \texttt{tolerance} argument may be supplied to define the maximum
permitted distance of a coordinate from a cell.

In parallel there are similar node-node graph restrictions for the discrete
function space for \texttt{y} to those for the \texttt{Interpolation} class
(section \ref{sect:Interpolation}).

\subsubsection{\texttt{LocalProjection}}

A \texttt{LocalProjection} is a subclass of the \texttt{EquationSolver} class,
and represents the solution of a projection problem, of the same type as
represented using a \texttt{Projection}, but using a local mass matrix solver.

The \texttt{LocalProjection} constructor has the form
\begin{lstlisting}
def __init__(self, x, rhs, *, form_compiler_parameters=None,
             cache_jacobian=None, cache_rhs_assembly=None,
             match_quadrature=None, defer_adjoint_assembly=None):
\end{lstlisting}
where \texttt{rhs} is a \texttt{ufl.classes.Form} or expression defining the
right-hand-side, and \texttt{x} is the \texttt{Function} being solved for.
Remaining constructor arguments are as for the \texttt{EquationSolver} class.

\subsection{Built-in \texttt{Equation} classes: Firedrake}

\subsubsection{\texttt{PointInterpolation}}

With the Firedrake backend, a \texttt{PointInterpolation} represents
interpolation of a given continuous scalar-valued function $\xi \in W$ onto a
given set of points,
\begin{equation*}
  \tilde{\psi} = P \tilde{\xi},
\end{equation*}
where the elements of $\tilde{\psi}$ are the interpolated values, $\tilde{\xi}$
is a vector whose elements are the discrete degrees of freedom for a continuous
scalar-valued function $\xi \in W$, and where $P$ is a matrix. A
\texttt{PointInterpolation} can be instantiated via
\begin{lstlisting}
eq = PointInterpolation(X, y, X_coords=X_coords)
\end{lstlisting}
where \texttt{X} is a sequence of scalars being solved for (for example each as
returned by the \texttt{new\_scalar\_function} function -- see section
\ref{sect:Assembly}) and \texttt{X\_coords} is a NumPy array defining the
coordinates at which to interpolate the \texttt{Function} \texttt{y}.

\subsubsection{\texttt{LocalProjection}}

A \texttt{LocalProjection} is a subclass of the \texttt{EquationSolver} class,
and represents the solution of a projection problem, of the same type as
represented using a \texttt{Projection}, but using a local mass matrix solver.

The \texttt{LocalProjection} constructor has the form
\begin{lstlisting}
def __init__(self, x, rhs, *, form_compiler_parameters=None,
             cache_jacobian=None, cache_rhs_assembly=None,
             match_quadrature=None, defer_adjoint_assembly=None):
\end{lstlisting}
where \texttt{rhs} is a \texttt{ufl.classes.Form} or expression defining
the right-hand-side, and \texttt{x} is the \texttt{Function} being solved for.
Remaining constructor arguments are as for the \texttt{EquationSolver} class.

\section{Custom \texttt{Equation} classes}\label{sect:custom}

Custom equations can be defined by inheriting from the \texttt{Equation} class,
and overriding key methods.

\subsection{Dependencies}

There are four important sets of forward equation dependencies
\begin{enumerate}
  \item Symbolic dependencies. Dependencies of a forward equation for which the
    Jacobian of the forward residual is non-zero, and for which associated
    terms appear in first order tangent-linear and first order adjoint
    equations.
  \item Non-linear dependencies. A subset of the symbolic dependencies.
    Dependencies of a forward equation which appear as dependencies of
    associated first order tangent-linear and first order adjoint calculations.
  \item Non-symbolic dependencies. Dependencies of a forward equation whose
    value is required in order to solve the equation, but for which the
    Jacobian of the forward residual is zero. Can include, for example, an
    initial guess supplied to an iterative solver used to solve the forward
    equation.
  \item Initial condition dependencies. Symbolic dependencies of a forward
    equation whose value prior to solving the equation is required in order to
    solve the equation. Can include, for example, the variable subsequently
    used to store the forward equation solution, if its value prior to solving
    the equation is used as an initial guess for an iterative solver used to
    solve the equation.
\end{enumerate}
The values of symbolic dependencies, non-symbolic dependencies, and initial
condition dependencies are required to solve the forward equation. The symbolic
dependencies are required in order to derive associated first order
tangent-linear and first order adjoint equations. The values of non-linear
dependencies are required in order to solve associated first order
tangent-linear and first order adjoint equations.

\subsection{Constructor}

A subclass of \texttt{Equation} must call the \texttt{Equation} constructor to
define dependencies. \texttt{tlm\_adjoint} does not distinguish between
symbolic and non-symbolic dependencies. The \texttt{Equation} constructor has
the form
\begin{lstlisting}
def __init__(self, x, deps, nl_deps=None,
             *, ic_deps=None, ic=None,
             adj_ic_deps=None, adj_ic=None,
             adj_type="conjugate_dual"):
\end{lstlisting}
with constructor arguments
\begin{itemize}
  \item \texttt{x}, a function, defining the solution to the equation.
  \item \texttt{deps}, a sequence of functions, defining the union of the
    symbolic and non-symbolic dependencies. Must include the solution to the
    equation.
  \item \texttt{nl\_deps}, a sequence of functions, defining the non-linear
    dependencies. If not supplied then set equal to \texttt{deps}.
  \item \texttt{ic\_deps}, a sequence of functions, defining the initial
    condition dependencies. Can contain only dependencies which are solutions
    to the equation.
  \item \texttt{ic}, if true sets \texttt{ic\_deps} to be the solution to the
    equation. Defaults to true if \texttt{ic\_deps} is \texttt{None}, and false
    otherwise.
  \item \texttt{adj\_ic\_deps}, a sequence of functions, defining adjoint
    initial condition dependencies. Can contain only dependencies which are
    solutions to the equation.
  \item \texttt{adj\_ic}, if true sets \texttt{adj\_ic\_deps} to be the
    solution to the equation. Defaults to true if \texttt{adj\_ic\_deps} is
    \texttt{None}, and false otherwise.
  \item \texttt{adj\_type}, ``primal'' or ``conjugate\_dual'', defining whether
    the adjoint is in the primal or conjugate dual space associated with the
    solution to the equation, \texttt{x}.
\end{itemize}

\subsection{Forward}

Given a forward residual function $F \left( x, y_0, y_1, \ldots \right)$, the
solution to the equation is defined via the root finding problem
\begin{equation*}
  F \left( \hat{x} \left( y_0, y_1, \ldots \right), y_0, y_1, \ldots \right)
    = 0
\end{equation*}
for all values of the dependencies $y_0$, $y_1$, $\ldots$ of interest.

The solution of the forward equation is defined by the \texttt{forward\_solve}
method. The \texttt{forward\_solve} method has the form
\begin{lstlisting}
def forward_solve(self, x, deps=None):
\end{lstlisting}
with arguments
\begin{itemize}
  \item \texttt{x}, a function, whose value should be set equal to the solution
    to the equation. If \texttt{deps} is supplied then \texttt{x} is contained
    in \texttt{deps}.
  \item \texttt{deps}, a sequence of functions containing values for the
    dependencies defined by \texttt{self.dependencies()}. If not supplied then
    the values contained in \texttt{self.dependencies()} should be used. If
    supplied, only the entry corresponding to \texttt{x} may be modified.
\end{itemize}

Equation processing by the currently active the \texttt{EquationManager} is
disabled (see section \ref{sect:EquationManager}) when the
\texttt{forward\_solve} method is called. If \texttt{deps} is not supplied,
then \texttt{self.drop\_references} (section \ref{sect:drop_references}) has
not previously been called prior to a call to the \texttt{forward\_solve}
method.

\subsection{Adjoint derivative action}\label{sect:adjoint_derivative_action}

Given the forward residual function $F \left( x, y_0, y_1, \ldots \right)$, an
adjoint model requires the ability to compute an adjoint derivative action,
e.g.
\begin{equation*}
  \frac{\partial F}{\partial y_i}^* \lambda_x,
\end{equation*}
for a given $\lambda_x$.

The action of the adjoint of the derivative of the forward residual is defined
by the \texttt{adjoint\_derivative\_action} method. The
\texttt{adjoint\_derivative\_action} method has the form
\begin{lstlisting}
def adjoint_derivative_action(self, nl_deps, dep_index, adj_x):
\end{lstlisting}
with arguments
\begin{itemize}
  \item \texttt{nl\_deps}, a sequence of functions containing values for the
    dependencies defined by \texttt{self.nonlinear\_dependencies()}. The
    dependencies must not be modified.
  \item \texttt{dep\_index}, an integer, defining the dependency with respect
    to which as derivative should be taken. The dependency is defined by
    \texttt{self.dependencies()[dep\_index]}.
  \item \texttt{adj\_x}, a function, equal to the value of the adjoint variable
    associated with the solution to the equation ($\lambda_x$ above). Must not
    be modified.
\end{itemize}
This method returns one of
\begin{itemize}
  \item \texttt{None}, if the adjoint derivative action is zero.
  \item A function containing the value of the adjoint derivative action.
  \item (FEniCS only) A vector containing the value of the adjoint derivative
    action.
  \item A tuple whose first element is an integer or float, and whose second
    element is a function or vector as defined above. The adjoint derivative
    action is equal to the product of the two elements.
  \item (FEniCS or Firedrake only) A \texttt{ufl.classes.Form}. Note that
    assembly with default form compiler parameters will later be used to
    assemble the form (possibly after addition to, or the addition of, other
    forms).
\end{itemize}
The return value will not be modified by calling code.

Equation processing by the currently active the \texttt{EquationManager} is
disabled (see section \ref{sect:EquationManager}) when the
\texttt{adjoint\_derivative\_action} method is called.
\texttt{self.drop\_references} (section \ref{sect:drop_references}) may have
been called prior to a call to the \texttt{adjoint\_derivative\_action} method.

\subsection{Adjoint Jacobian solve}

Given the forward residual function $F \left( x, y_0, y_1, \ldots \right)$, an
adjoint model requires the ability to solve an equation involving the adjoint
Jacobian, i.e. to solve for $\lambda_x$ in
\begin{equation*}
  \frac{\partial F}{\partial x}^* \lambda_x = b,
\end{equation*}
for a given $b$.

The action of the inverse of the adjoint of the forward Jacobian is defined by
the \texttt{adjoint\_jacobian\_solve} method. The
\texttt{adjoint\_jacobian\_solve} method has the form
\begin{lstlisting}
def adjoint_jacobian_solve(self, adj_x, nl_deps, b):
\end{lstlisting}
with arguments
\begin{itemize}
  \item \texttt{adj\_x}, an initial guess for the adjoint solve, or
    \texttt{None} if the \texttt{Equation} does not accept an initial guess.
    May be modified or returned.
  \item \texttt{nl\_deps}, a sequence of functions containing values for the
    dependencies defined by \texttt{self.nonlinear\_dependencies()}. The
    dependencies must not be modified.
  \item \texttt{b}, a function, defining the right-hand-side of the linear
    system ($b$ above). May be modified or returned.
\end{itemize}
This method returns a function defining the solution of the linear system
($\lambda_x$ above). The return value will not be modified by calling code. A
return value of \texttt{None} can be used to indicate that the solution is
zero.

Equation processing by the currently active the \texttt{EquationManager} is
disabled (see section \ref{sect:EquationManager}) when the
\texttt{adjoint\_derivative\_action} method is called.
\texttt{self.drop\_references} (section \ref{sect:drop_references}) may have
been called prior to a call to the \texttt{adjoint\_jacobian\_solve} method.

\subsection{Adjoint optimization}

The \texttt{subtract\_adjoint\_derivative\_actions} method may be defined to
compute multiple adjoint derivative actions, and to subtract them from
associated adjoint equation right-hand-sides. An \texttt{Equation} which
defines a \texttt{subtract\_adjoint\_derivative\_actions} method need not
define an \texttt{adjoint\_derivative\_action} method.

The \texttt{subtract\_adjoint\_derivative\_actions} method has the form
\begin{lstlisting}
def subtract_adjoint_derivative_actions(self, adj_x, nl_deps, dep_Bs):
\end{lstlisting}
\texttt{adj\_x} and \texttt{nl\_deps} are as for the
\texttt{adjoint\_derivative\_action} method. \texttt{dep\_Bs} is a dictionary
of \texttt{dep\_index: dep\_B} pairs, where each \texttt{dep\_B} is an
\texttt{AdjointRHS} which should be updated by subtracting derivative
information computed by differentiating with respect to
\texttt{self.dependencies()[dep\_index]}, using the \texttt{dep\_B.sub} method.
For example, a basic version of \texttt{subtract\_adjoint\_derivative\_actions}
which makes use of \texttt{adjoint\_derivative\_action} has the form
\begin{lstlisting}
def subtract_adjoint_derivative_actions(self, adj_x, nl_deps, dep_Bs):
    for dep_index, dep_B in dep_Bs.items():
        dep_B.sub(self.adjoint_derivative_action(nl_deps, dep_index, adj_x))
\end{lstlisting}

\subsection{Tangent-linear}\label{sect:tangent_linear}

Given the forward residual function $F \left( x, y_0, y_1, \ldots, m \right)$,
a control $m$, and a direction $\zeta$, a corresponding tangent-linear equation
is defined
\begin{equation*}
  \frac{\partial F}{\partial x} \tau_x
    + \frac{\partial F}{\partial y_0} \tau_{y_0}
    + \frac{\partial F}{\partial y_1} \tau_{y_1}
    + \ldots = -\frac{\partial F}{\partial m} \zeta,
\end{equation*}
where $\tau_x$, $\tau_{y_0}$, $\tau_{y_1}$, \ldots are tangent-linear
variables.

Tangent-linear equations are derived using the \texttt{tangent\_linear} method.
The \texttt{tangent\_linear} method has the form
\begin{lstlisting}
def tangent_linear(self, M, dM, tlm_map):
\end{lstlisting}
with arguments
\begin{itemize}
  \item \texttt{M}, a sequence of functions, defining the control ($m$ above).
  \item \texttt{dM}, a sequence of functions, defining the direction ($\zeta$
    above).
  \item \texttt{tlm\_map}, a \texttt{TangentLinearMap}, allowing tangent-linear
    variables to be accessed.
\end{itemize}
This method returns an \texttt{Equation} object defining the tangent-linear
equation

Given a dependency of the \texttt{Equation} \texttt{dep}, a corresponding
tangent-linear variable can be accessed using the \texttt{get\_tangent\_linear}
function, e.g.
\begin{lstlisting}
tau_dep = get_tangent_linear(dep, M, dM, tlm_map)
\end{lstlisting}
This returns a direction (an element of \texttt{dM}), a tangent-linear solution
variable, or \texttt{None} if the tangent-linear variable is known to be
identically zero.

\texttt{self.drop\_references} (section \ref{sect:drop_references}) will not
previously been called prior to a call to the \texttt{tangent\_linear} method.

\subsection{Solving for multiple functions}

An \texttt{Equation} may solve for two or more functions. In this case the
arguments \texttt{x}, \texttt{adj\_x}, and \texttt{b} in the above should be
capitalized \texttt{X}, \texttt{adj\_X}, and \texttt{B}, and should each be a
sequence of functions. The return value of \texttt{adjoint\_jacobian\_solve}
should also be a sequence of functions. \texttt{adj\_type} may be a sequence
with elements equal to ``primal'' or ``conjugate\_dual''.

\subsection{Dropping references}\label{sect:drop_references}

If a subclassed \texttt{Equation} keeps references to any functions, then it
should be possible to drop these references with the \texttt{drop\_references}
method. This method takes the form
\begin{lstlisting}
def drop_references(self):
\end{lstlisting}
The \texttt{drop\_references} method must call the base class
\texttt{drop\_references} method.

\section{Linear algebra}

\subsection{\texttt{LinearEquation}}

A \texttt{LinearEquation} is an \texttt{Equation} representing
\begin{equation*}
  A x = \sum_{i = 1}^N b_i,
\end{equation*}
where $A$ is a matrix and the $b_i$ are independent of $x$.

The \texttt{LinearEquation} constructor has the form
\begin{lstlisting}
def __init__(self, X, B, *, A=None, adj_type=None):
\end{lstlisting}
with constructor arguments
\begin{itemize}
  \item \texttt{X}, a function, or a sequence of functions, defining $x$.
  \item \texttt{B}, a \texttt{RHS}, or a sequence of \texttt{RHS} objects,
    defining the $b_i$.
  \item \texttt{A}, a \texttt{Matrix}. If not provided $A$ is an identity
    matrix.
  \item \texttt{adj\_type}, as for the \texttt{Equation} constructor. Defaults
    to ``primal'' if \texttt{A} is supplied, and ``conjugate\_dual'' otherwise.
\end{itemize}

\subsection{\texttt{Matrix}}

The \texttt{Matrix} class is an abstract base class, and can be used to define
matrices as used by a \texttt{LinearEquation}.

\subsubsection{Constructor}

A subclass of \texttt{Matrix} must call the \texttt{Matrix} constructor to
define dependencies. The \texttt{Matrix} constructor has the form
\begin{lstlisting}
def __init__(self, nl_deps=None, *, ic=True, adj_ic=True):
\end{lstlisting}
with constructor arguments
\begin{itemize}
  \item \texttt{nl\_deps}, a sequence of functions, defining the dependencies
    of the matrix.
  \item \texttt{ic}. If true then in solving a linear equation involving the
    matrix the solution variable is an initial condition dependency of the
    equation.
  \item \texttt{adj\_ic}. If true then in solving an adjoint equation
    involving the matrix the solution variable is an adjoint initial
    condition dependency of the equation.
\end{itemize}

\subsubsection{Matrix action}

The value of a matrix action $A x$ is defined by the \texttt{forward\_action}
method. The \texttt{forward\_action} method has the form
\begin{lstlisting}
def forward_action(self, nl_deps, x, b, *, method="assign"):
\end{lstlisting}
with arguments
\begin{itemize}
  \item \texttt{nl\_deps}, a sequence of functions containing values for the
    dependencies defined by \texttt{self.nonlinear\_dependencies()}. The
    dependencies must not be modified.
  \item \texttt{x}, a function, defining $x$. Must not be modified.
  \item \texttt{b}, a function, defining the result of the matrix action. Set
    or modified by this method.
  \item \texttt{method}, a string. One of
  \begin{itemize}
    \item ``assign'', \texttt{b} is set equal to the result of the matrix
      action.
    \item ``add'', the result of the matrix action is added to \texttt{b}.
    \item ``sub'', the result of the matrix action is subtracted from
      \texttt{b}.
  \end{itemize}
\end{itemize}

\subsubsection{Adjoint matrix action}

The value of a matrix action $A^* x$ is defined by the
\texttt{adjoint\_action} method. The \texttt{adjoint\_action} method has the
form
\begin{lstlisting}
def adjoint_action(self, nl_deps, adj_x, b, b_index=0, *, method="assign"):
\end{lstlisting}
with arguments
\begin{itemize}
  \item \texttt{nl\_deps}, as in the \texttt{forward\_action} method.
  \item \texttt{adj\_x}, a function, defining $x$. Must not be modified.
  \item \texttt{b}, a function, defining the result of the matrix action. Set
    or modified by this method.
  \item \texttt{b\_index}, see section \ref{sect:Matrix_multiple}
  \item \texttt{method}, as in the \texttt{forward\_action} method.
\end{itemize}

\subsubsection{Matrix solve}

The value of an inverse matrix action $A^{-1} b$ is defined by the
\texttt{forward\_solve} method. The \texttt{forward\_solve} method has the
form
\begin{lstlisting}
def forward_solve(self, x, nl_deps, b):
\end{lstlisting}
with arguments
\begin{itemize}
  \item \texttt{x}, the result of the inverse matrix action, set by this
    method.
  \item \texttt{nl\_deps}, as in the \texttt{forward\_action} method.
  \item \texttt{b}, the right-hand-side of the linear system to be solved. May
    be modified.
\end{itemize}

\subsubsection{Adjoint matrix solve}

The value of an inverse adjoint matrix action $A^{-*} b$ is defined by the
\texttt{adjoint\_solve} method. The \texttt{adjoint\_solve} method has the
form
\begin{lstlisting}
def adjoint_solve(self, adj_x, nl_deps, b):
\end{lstlisting}
with arguments
\begin{itemize}
  \item \texttt{adj\_x}, an initial guess, or \texttt{None} if the
    \texttt{Matrix} does not accept an adjoint initial guess. May be modified
    or returned.
  \item \texttt{nl\_deps}, as in the \texttt{forward\_action} method.
  \item \texttt{b}, the right-hand-side of the linear system to be solved. May
    be modified or returned.
\end{itemize}
The method returns the result as a function. The return value will not be
modified by calling code.

\subsubsection{Adjoint derivative action}

The action of the adjoint of the derivative of $A x$ is defined by the
\texttt{adjoint\_derivative\_action} method. The
\texttt{adjoint\_derivative\_action} method has the form
\begin{lstlisting}
def adjoint_derivative_action(self, nl_deps, nl_dep_index, x, adj_x, b, *,
                              method="assign"):
\end{lstlisting}
with arguments
\begin{itemize}
  \item \texttt{nl\_deps}, as in the \texttt{forward\_action} method.
  \item \texttt{nl\_dep\_index}, an integer defining the dependency in
    \texttt{self.nonlinear\_dependencies()} with respect to which a derivative
    should be taken.
  \item \texttt{x}, a function, defining $x$ in the matrix action $A x$. Must
    not be modified.
  \item \texttt{adj\_x}, a function, on which the adjoint of the derivative
    acts. Must not not be modified.
  \item \texttt{b}, a function defining the result. Set or modified by this
    method.
  \item \texttt{method}, as in the \texttt{forward\_action} method.
\end{itemize}

\subsubsection{Tangent-linear}

Tangent-linear information is defined by the \texttt{tangent\_linear\_rhs}
method. The \texttt{tangent\_linear\_rhs} method has the form
\begin{lstlisting}
def tangent_linear_rhs(self, M, dM, tlm_map, x):
\end{lstlisting}
with arguments
\begin{itemize}
  \item \texttt{M}, a sequence of functions, defining the control.
  \item \texttt{dM}, a sequence of functions, defining the direction.
  \item \texttt{tlm\_map}, a \texttt{TangentLinearMap}, allowing tangent-linear
    variables to be accessed.
  \item \texttt{x}, a function.
\end{itemize}
This method should return tangent-linear terms associated with a forward term
of the form $A x$, where the \texttt{Matrix} defines $A$ and the argument
\texttt{x} defines $x$. This method may return \texttt{None} (if there are no
terms), a \texttt{RHS}, or a sequence of \texttt{RHS} objects.

\subsubsection{Matrices acting on multiple functions}\label{sect:Matrix_multiple}

A \texttt{Matrix} may act on multiple functions. In this case methods have the
form
\begin{lstlisting}
def forward_action(self, nl_deps, X, B, *, method="assign"):
\end{lstlisting}
\begin{lstlisting}
def adjoint_action(self, nl_deps, adj_X, b, b_index=0, *, method="assign"):
\end{lstlisting}
\begin{lstlisting}
def forward_solve(self, X, nl_deps, B):
\end{lstlisting}
\begin{lstlisting}
def adjoint_solve(self, adj_X, nl_deps, B):
\end{lstlisting}
\begin{lstlisting}
def adjoint_derivative_action(self, nl_deps, nl_dep_index, X, adj_X, b, *,
                              method="assign"):
\end{lstlisting}
\begin{lstlisting}
def tangent_linear_rhs(self, M, dM, tlm_map, X):
\end{lstlisting}
where \texttt{X}, \texttt{adj\_X}, and \texttt{B} are now each a sequence of
functions (except in the case of \texttt{adjoint\_solve}, where \texttt{adj\_X}
may be \texttt{None} if no adjoint initial guess is provided). The return value
of \texttt{forward\_solve} and \texttt{adjoint\_solve} should also be a
sequence of functions. The \texttt{b} argument of \texttt{adjoint\_action} is
equal to \texttt{B[b\_index]}.

\subsubsection{Dropping references}

If a subclassed \texttt{Matrix} keeps references to any functions, then it
should be possible to drop these references with the \texttt{drop\_references}
method. This method takes the form
\begin{lstlisting}
def drop_references(self):
\end{lstlisting}
The \texttt{drop\_references} method must call the base class
\texttt{drop\_references} method.

\subsection{\texttt{RHS}}

The \texttt{RHS} class is an abstract base class, and can be used to define
right-hand-side terms as used by a \texttt{LinearEquation}.

\subsubsection{Constructor}

A subclass of \texttt{RHS} must call the \texttt{RHS} constructor to define
dependencies. The \texttt{RHS} constructor has the form
\begin{lstlisting}
def __init__(self, deps, nl_deps=None):
\end{lstlisting}
with constructor arguments
\begin{itemize}
  \item \texttt{deps}, a sequence of functions, defining the union of the
    symbolic and non-symbolic dependencies of the right-hand-side.
  \item \texttt{nl\_deps}, a sequence of functions, defining the non-linear
    dependencies of the right-hand-side. If not supplied then set equal to
    \texttt{deps}.
\end{itemize}

\subsubsection{Forward}

The \texttt{add\_forward} method adds the right-hand-side term. The
\texttt{add\_forward} method has the form
\begin{lstlisting}
def add_forward(self, b, deps):
\end{lstlisting}
with arguments
\begin{itemize}
  \item \texttt{b}, a function. The function to which the right-hand-side
    should be added. Should be modified by this method.
  \item \texttt{deps}, a sequence of functions containing values for the
    dependencies defined by \texttt{self.dependencies()}. The dependencies must
    not be modified.
\end{itemize}

\subsubsection{Adjoint derivative action}

The action of the adjoint of the derivative of the right-hand-side term is
subtracted by the \texttt{subtract\_adjoint\_derivative\_action} method. The
\texttt{subtract\_adjoint\_derivative\_action} method has the form
\begin{lstlisting}
def subtract_adjoint_derivative_action(self, nl_deps, dep_index, adj_x, b):
\end{lstlisting}
with arguments
\begin{itemize}
  \item \texttt{nl\_deps}, a sequence of functions containing values for the
    dependencies defined by \texttt{self.nonlinear\_dependencies()}. The
    dependencies must not be modified.
  \item \texttt{dep\_index}, an integer, defining the dependency with respect
    to which as derivative should be taken. The dependency is defined by
    \texttt{self.dependencies()[dep\_index]}.
  \item \texttt{adj\_x}, a function, on which the adjoint of the derivatives
    act. Must not not be modified.
  \item \texttt{b}, a function, from which the adjoint derivative action should
    be subtracted.
\end{itemize}

\subsubsection{Tangent-linear}

The \texttt{tangent\_linear\_rhs} method constructs tangent-linear
right-hand-side terms. The \texttt{tangent\_linear\_rhs} method has the form
\begin{lstlisting}
def tangent_linear_rhs(self, M, dM, tlm_map):
\end{lstlisting}
with arguments as in the \texttt{Equation.tangent\_linear} method. This method
may return \texttt{None} (if there are no terms), a \texttt{RHS}, or a sequence
of \texttt{RHS} objects.

\subsubsection{Multiple functions}

A \texttt{RHS} may be defined using multiple functions. In this case methods
have the form
\begin{lstlisting}
def add_forward(self, B, deps):
\end{lstlisting}
\begin{lstlisting}
def subtract_adjoint_derivative_action(self, nl_deps, dep_index, adj_X, b):
\end{lstlisting}
where \texttt{adj\_X} and \texttt{B} are now each a sequence of functions. 

\subsubsection{Dropping references}

If a subclassed \texttt{RHS} keeps references to any functions, then it should
be possible to drop these references with the \texttt{drop\_references} method.
This method takes the form
\begin{lstlisting}
def drop_references(self):
\end{lstlisting}
The \texttt{drop\_references} method must call the base class
\texttt{drop\_references} method.

\subsection{Built-in linear algebra classes}

\subsubsection{\texttt{InnerProductRHS} and \texttt{InnerProduct}}

An \texttt{InnerProductRHS} is a \texttt{RHS} representing a right-hand-side
term of the form
\begin{equation*}
  b_i = \alpha \sum_{j,k} z_j^* M_{j,k} y_k.
\end{equation*}
Here the $z_j$ and $y_k$ are the degrees of freedom for two functions, which
may be the same function. $b_i$ are the degrees of freedom for the resulting
right-hand-side term. The $M_{j,k}$ are the elements of some given matrix
(which should typically be Hermitian positive definite), and $\alpha$ is some
scalar constant. An \texttt{InnerProduct} is a \texttt{LinearEquation}
representing
\begin{equation*}
  x_i = \alpha \sum_{j,k} z_j^* M_{j,k} y_k,
\end{equation*}
solving for $x$, whose degrees of freedom are the $x_i$.

An \texttt{InnerProductRHS} can be instantiated via
\begin{lstlisting}
b = InnerProductRHS(y, z, alpha=alpha, M=M)
\end{lstlisting}
where \texttt{y} and \texttt{z} are each functions whose degrees of freedom are
the $y_j$ and $z_k$, \texttt{alpha} is a given floating point value defining
$\alpha$ (set equal to $1.0$ if not supplied), and \texttt{M} is a
\texttt{Matrix} whose elements are the $M_{j,k}$ (set equal to an identity
matrix if not supplied). An \texttt{InnerProduct} can be instantiated via
\begin{lstlisting}
eq = InnerProduct(x, y, z, alpha=alpha, M=M)
\end{lstlisting}
where \texttt{x} is the function being solved for.

\subsubsection{\texttt{MatrixActionRHS}}

A \texttt{MatrixActionRHS} is a \texttt{RHS} representing a right-hand-side
term resulting from a matrix action,
\begin{equation*}
  b = A y.
\end{equation*}

A \texttt{MatrixActionRHS} can be instantiated via
\begin{lstlisting}
b = MatrixActionRHS(A, Y)
\end{lstlisting}
where \texttt{A} is a \texttt{Matrix} defining the matrix $A$, and \texttt{Y}
is a function, or a sequence of functions, defining $y$.

\section{Custom storage}

Custom loading or saving of data is facilitated by \texttt{Storage} classes.
These can, for example, be used to load observational data from disk, for use
in defining mis-match functionals.

\subsection{\texttt{Storage}}

The \texttt{Storage} class is an abstract subclass of \texttt{Equation}, used
to load or save data associated with a function.

The data associated with a given function is associated with a string key. In
a \texttt{forward\_solve} call, if the key is present in the storage then
\texttt{x} is set equal to the data stored with this key. If the key is not
present in the storage then, if saving of data is enabled, data associated with
\texttt{x} is stored with this key. This latter behaviour may be useful for the
case where a forward calculation is used to define reference data.

\subsection{Built-in \texttt{Storage} classes}

\subsubsection{\texttt{MemoryStorage}}

Memory storage. A \texttt{MemoryStorage} can be instantiated via
\begin{lstlisting}
eq = MemoryStorage(x, d, key, save=save)
\end{lstlisting}
with constructor arguments
\begin{itemize}
  \item \texttt{x}, the function being loaded or saved ($x$ in the above).
  \item \texttt{d}, a dictionary, in which data is stored.
  \item \texttt{key}, the string key discussed above.
  \item \texttt{save}, whether saving is enabled, default false.
\end{itemize}

\subsubsection{\texttt{HDF5Storage}}

Storage using the HDF5 format \citep{hdf52021} using the \texttt{h5py} library.
An \texttt{HDF5Storage} can be instantiated via
\begin{lstlisting}
eq = HDF5Storage(x, h, key, save=save)
\end{lstlisting}
where \texttt{h} is an \texttt{h5py} \texttt{File}, and other arguments are as
for the \texttt{MemoryStorage} class.

\subsection{Custom \texttt{Storage} classes}

Custom \texttt{Storage} can be defined by inheriting from the \texttt{Storage}
class, and overriding key methods.

\subsubsection{Constructor}

A subclass of \texttt{Storage} must call the \texttt{Storage} constructor. The
\texttt{Storage} constructor has the form
\begin{lstlisting}
def __init__(self, x, key, *, save=False):
\end{lstlisting}
with constructor arguments
\begin{itemize}
  \item \texttt{x}, a function, defining the solution to the equation.
  \item \texttt{key}, a string, defining the key.
  \item \texttt{save}, a logical, whether to enable saving.
\end{itemize}

\subsubsection{Storing and loading data}

The \texttt{is\_saved} method indicates if data is stored with the given key.
The \texttt{is\_saved} method has the form
\begin{lstlisting}
def is_saved(self):
\end{lstlisting}
returning true if data is stored with the key \texttt{self.key()}, and false
otherwise.

The \texttt{save} method stores data with the given key. The \texttt{save}
method has the form
\begin{lstlisting}
def save(self, x):
\end{lstlisting}
where \texttt{x} is a function defining the data to be stored with the
key \texttt{self.key()}.

The \texttt{load} method loads data associated with the given key. The
\texttt{load} method has the form
\begin{lstlisting}
def load(self, x):
\end{lstlisting}
where \texttt{x} is a function. \texttt{x} should be set by this method, using
data stored with the key \texttt{self.key()}.

\section{Functionals}\label{sect:Functional} 

\subsection{Instantiation}

Functionals are defined using a \texttt{Functional} object. A
\texttt{Functional} can be instantiated via
\begin{lstlisting}
J = Functional(name=name)
\end{lstlisting}
where \texttt{name} is a name for the \texttt{Functional}. On instantiation the
value of the \texttt{Functional} is zero.

\subsection{Adding terms}

The value of the \texttt{Functional} can be set by calling its \texttt{assign}
method
\begin{lstlisting}
J.assign(term)
\end{lstlisting}
where \texttt{term} is either an appropriate function (see section
\ref{sect:Functional_internals}) or (with the FEniCS or Firedrake backends) a
\texttt{ufl.classes.Form} representing a term in the functional.

Further terms can be added to the \texttt{Functional} by calling its
\texttt{addto} method
\begin{lstlisting}
J.addto(term)
\end{lstlisting}
where \texttt{term} is again either an appropriate function (see section
\ref{sect:Functional_internals}) or a \texttt{ufl.classes.Form} representing a
term in the functional.

The value of the functional can be accessed using its \texttt{value} method,
which returns a float
\begin{lstlisting}
J_val = J.value()
\end{lstlisting}

\subsection{Internal function}\label{sect:Functional_internals}

Internally a \texttt{Functional} object stores the value of the
\texttt{Functional} in an appropriate function. By default this internal
function is defined to be a function as returned by
\texttt{new\_scalar\_function()} (see section \ref{sect:Assembly}).

In advanced usage the function space for the internal function may be specified
\begin{lstlisting}
J = Functional(name=name, space=space)
\end{lstlisting}
The internal function may be accessed via
\begin{lstlisting}
J_fn = J.function()
\end{lstlisting}
and then the function may, for example, be defined to be the solution of an
\texttt{Equation}. Note that new internal functions are generated by calls to
the \texttt{Functional.assign} or \texttt{Functional.addto} methods.

\section{First order adjoint}\label{sect:first_order_adjoint}

When the \texttt{solve} method of an \texttt{Equation} object is called, the
\texttt{Equation} is processed by an internal \texttt{EquationManager} (see
section \ref{sect:EquationManager}). This records information about the
dependencies of the equation, for use in checkpointing (section
\ref{sect:checkpointing}) or for use in adjoint calculations, and further
derives tangent-linear equations as required (section \ref{sect:higher_order}).

After all forward equations have been solved the derivative of a functional
with respect to a control variable can be computed using the
\texttt{compute\_gradient} function. This constructs and solves adjoint
equations and, depending on the checkpointing configuration, may solve forward
equations so as to regenerate required forward solution data.

The basic syntax of the \texttt{compute\_gradient} function is
\begin{lstlisting}
dJ = compute_gradient(J, m)
\end{lstlisting}
where \texttt{J} is a \texttt{Functional} and \texttt{m} a function. This
returns a function storing the values of the derivative, where specifically the
$i$th degree of freedom in \texttt{dJ} corresponds to the derivative of the
functional defined by \texttt{J} with respect to the $i$th degree of freedom of
\texttt{m}.

The derivative with respect to multiple controls can be computed via for
example
\begin{lstlisting}
dJ_m_0, dJ_m_1, dJ_m_2 = compute_gradient(J, (m_0, m_1, m_2))
\end{lstlisting}
The derivative of multiple functionals can be computed via for example
\begin{lstlisting}
dJ_0, dJ_1, dJ_2 = compute_gradient((J_0, J_1, J_2), m)
\end{lstlisting}
although note that this requires the solution of multiple sets of adjoint
equations. The derivative of multiple functionals with respect to multiple
controls can be computed via for example
\begin{lstlisting}
((dJ_0_m_0, dJ_0_m_1, dJ_0_m_2),
 (dJ_1_m_0, dJ_1_m_1, dJ_1_m_2),
 (dJ_2_m_0, dJ_2_m_1, dJ_2_m_2)) = \
    compute_gradient((J_0, J_1, J_2), (m_0, m_1, m_2))
\end{lstlisting}

Note that the \texttt{compute\_gradient} method finalizes the internal
\texttt{EquationManager} (see section \ref{sect:EquationManager_state}).

The degrees of freedom associated with functions returned by
\texttt{compute\_gradient} are the complex conjugate of linear sensitivities.

\section{Tangent-linear and higher order adjoint}\label{sect:higher_order}

\subsection{First order tangent-linear}

The derivation and solution of tangent-linear equations can be enabled by
calling the \texttt{configure\_tlm} function before forward equations are
solved.

\begin{lstlisting}
configure_tlm((m_0, zeta_0))
\end{lstlisting}
enables the automated derivation and solution of first order tangent-linear
equations, computing the derivative with respect to the function \texttt{m}
with direction defined by the function \texttt{zeta\_0}.

\subsection{Higher order tangent-linear}

The derivation and solution of higher-order tangent-linear equations can be
enabled by supplying \texttt{configure\_tlm} with further arguments.

\begin{lstlisting}
configure_tlm((m_0, zeta_0), (m_1, zeta_1))
\end{lstlisting}
enables the automated derivation and solution of second order tangent-linear
equations, computing second derivative information. This also enables the
automated derivation and solution of any required first order tangent-linear
equations.

\subsection{Higher order adjoint}\label{sect:higher_order_adjoint}

If a first order tangent-linear calculation is performed, defined by
differentiation with respect to $m$ with direction $\zeta$, then the
tangent-linear variable associated with a functional $J$ is the forward model
constrained derivative of $J$ with respect to $m$ evaluated with direction
$\zeta$.

Given a \texttt{Functional} object \texttt{J}, a new \texttt{Functional} object
associated with such a first order sensitivity can be obtained via its
\texttt{tlm\_functional} method
\begin{lstlisting}
configure_tlm((m, zeta))

[... forward model ...]

J = Functional(name="J")
J.assign([...])
J_tlm = J.tlm_functional((m, zeta))
\end{lstlisting}
The action of the second derivative of \texttt{J} on \texttt{zeta} can now be
computed by an adjoint calculation associated with the \texttt{Functional}
\texttt{J\_tlm}
\begin{lstlisting}
ddJ = compute_gradient(J_tlm, m)
\end{lstlisting}

This generalizes to higher order in the natural way, for example for a fourth
order derivative calculation
\begin{lstlisting}
configure_tlm((m_0, zeta_0), (m_1, zeta_1), (m_1, zeta_1))

[... forward model ...]

J = Functional(name="J")
J.assign([...])
J_tlm_3 = J.tlm_functional((m_0, zeta_0), (m_1, zeta_1), (m_1, zeta_1))

ddddJ = compute_gradient(J_tlm_3, m)
\end{lstlisting}

As before, the degrees of freedom associated with functions returned by
\texttt{compute\_gradient} are the complex conjugate of sensitivities.

\subsection{Hessian actions}\label{sect:Hessian}

Subclasses of \texttt{Hessian} facilitate the calculation of forward model
constrained Hessian actions. There are two types -- \texttt{GeneralHessian},
which can be used with any checkpointing method, and \texttt{CachedHessian},
which uses caching to avoid rerunning.

\subsubsection{Hessian actions without caching}

A \texttt{GeneralHessian} can be instantiated via
\begin{lstlisting}
H = Hessian(forward)
\end{lstlisting}
where \texttt{forward} is a callable which takes as input one or more functions
defining the control and its value, and which returns the \texttt{Functional}.

A first order derivative can subsequently be computed using the
\texttt{GeneralHessian.compute\_gradient} method
\begin{lstlisting}
dJ = H.compute_gradient(m)
\end{lstlisting}
where \texttt{m} is a function or a sequence of functions defining the value of
the control. The forward model is first rerun using the \texttt{forward}
callable prior to the first order adjoint calculation. The degrees of
freedom associated with \texttt{dJ} are the complex conjugate of linear
sensitivities.

The action of the Hessian can be computed using the
\texttt{GeneralHessian.action} method
\begin{lstlisting}
J_val, dJ_val, ddJ = H.action(m, dm)
\end{lstlisting}
where \texttt{m} and \texttt{dm} are each a function or a sequence of
functions. The forward model is first rerun using the \texttt{forward} callable
prior to the second order adjoint calculation. This method returns the value of
the functional, the first derivative of the functional evaluated with direction
\texttt{dm}, and the action of the Hessian on \texttt{dm}. The degrees of
freedom associated with \texttt{ddJ} are the complex conjugate of the Hessian
action degrees of freedom.

\subsubsection{Hessian actions with caching}

For small problems it may be possible to store the entire forward solution in
memory without the use of checkpointing and rerunning (section
\ref{sect:checkpointing}). The \texttt{CachedHessian} class is an optimized
subclass for this case.

A \texttt{CachedHessian} can be instantiated via
\begin{lstlisting}
H = CachedHessian(J)
\end{lstlisting}
where \texttt{J} is the functional of interest. It defines
\texttt{compute\_gradient} and \texttt{action} methods with the same interface
as those of the \texttt{GeneralHessian} class.

The \texttt{CachedHessian} class requires the use of the ``memory''
checkpointing method, and for weak referencing of \texttt{Equation} objects to
be disabled (section \ref{sect:configure_checkpointing_memory}).

\section{Verification}\label{sect:verification}

\subsection{Functional Taylor remainder}

A Taylor verification of a first or second order adjoint calculation, using the
approach described in \citet{farrell2013}, can be performed using the
\texttt{taylor\_test} function. The interface for this function (which is based
upon the interface for the \texttt{taylor\_test} function in dolfin-adjoint
2017.1.0) is
\begin{lstlisting}
def taylor_test(forward, M, J_val, dJ=None, ddJ=None, seed=1.0e-2, dM=None,
                M0=None, size=5, manager=None):
\end{lstlisting}
with arguments
\begin{itemize}
  \item \texttt{forward}, a callable, which takes as input one or more
    functions defining the control, and returns the functional.
  \item \texttt{M}, a function, or a sequence of functions, defining the
    control.
  \item \texttt{J\_val}, a float, defining the value of the functional at the
    unperturbed reference value for the control.
  \item \texttt{dJ}, a function, or a sequence of functions, defining the value
    of the forward model constrained derivative as returned by
    \texttt{compute\_gradient}. Required if \texttt{ddJ} is not supplied.
  \item \texttt{ddJ}, a \texttt{Hessian}, used for second order adjoint
    verification.
  \item \texttt{seed}, a \texttt{float}, controlling the magnitude of control
    perturbations.
  \item \texttt{dM}, a function, or a sequence of functions, defining the
    direction of control perturbations. If not supplied then a perturbation
    direction whose degrees of freedom are uniform random values in $\left[ 0,
    1 \right)$ (generated using the NumPy \texttt{numpy.random.random}
    function) is used.
  \item \texttt{M0}, a function, or a sequence of functions, defining the value
    of the unperturbed reference value for the control. \texttt{M} is used if
    not supplied.
  \item \texttt{size}, an integer, the number of control perturbations.
    Perturbations whose degrees of freedom are $\alpha 2^{-p}$ times
    \texttt{seed} times the values of the degrees of freedom of \texttt{dM} are
    used, where $p$ ranges from $0$ to \texttt{size - 1}, and where $\alpha =
    \max \left( 1, \max_i \left| \tilde{m}_i \right| \right)$, where the
    $\tilde{m}_i$ are the discrete degrees of freedom associated with the
    \texttt{M0}. The forward model is rerun using the \texttt{forward} callable
    for each perturbation.
\end{itemize}

The verification performed by \texttt{taylor\_test} is based upon the
calculation of the magnitude of Taylor corrected functional changes
\citep{farrell2013}
\begin{align*}
  e_{0,1} \left( \varepsilon \right) & = \left|
    \hat{J} \left( m_0 + \varepsilon \zeta \right)
    - \hat{J} \left( m_0 \right)
    - \varepsilon \left. \frac{\mathrm{d} \hat{J}}{\mathrm{d} m} \right|_{m = m_0} \zeta
    \right| = {\cal O} \left( \varepsilon^2 \right), \\
  e_{0,2} \left( \varepsilon \right) & = \left|
    \hat{J} \left( m_0 + \varepsilon \zeta \right) - \hat{J} \left( m_0 \right)
    - \varepsilon \left. \frac{\mathrm{d} \hat{J}}{\mathrm{d} m} \right|_{m = m_0} \zeta
    - \frac{1}{2} \varepsilon^2 \left. \frac{\mathrm{d}}{\mathrm{d} m} \left( \frac{\mathrm{d} \hat{J}}{\mathrm{d} m} \zeta \right) \right|_{m = m_0} \zeta
    \right| = {\cal O} \left( \varepsilon^3 \right),
\end{align*}
where $\hat{J} \left( m \right)$ defines the value of the functional, evaluated
after solving the forward model with a given value for the control.

When called the \texttt{taylor\_test} function displays the magnitudes of the
changes of the functional value for each perturbed control, and the implied
orders of convergence between subsequent pairs of these, first for the case
where no derivative information is used, and then for the case where first
order (if \texttt{ddJ} is not supplied) or the case where first and second
order (if \texttt{ddJ} is supplied) derivative information is used. The
function returns the minimum order of convergence computed in the latter case,
where derivative information is used.

In a valid verification, for sufficiently small perturbation magnitude the
order of convergence when no derivative information is used should be
approximately one. If only first derivative information is used then for
sufficiently small perturbation magnitude the order of convergence should be
approximately two. If first and second derivative information is used then for
sufficiently small perturbation magnitude the order of convergence should be
approximately three. Numerical roundoff issues, or encountering a special case
where the first or second order derivatives are zero, may prevent these
asymptotic convergence orders from being observable.

\subsection{Functional derivative Taylor remainder}

The \texttt{taylor\_test\_tlm} and \texttt{taylor\_test\_tlm\_adjoint}
functions can be used for further testing of tangent-linear models, and higher
order adjoint adjoint models. These are based upon the calculation of the
magnitude of Taylor corrected functional gradient changes.

For example a second order test is based on
\begin{equation*}
  e_{1,1} \left( \varepsilon \right) = \left|
    \left. \frac{\mathrm{d} \hat{J}}{\mathrm{d} m} \right|_{m = m_0 + \zeta} \chi
    - \left. \frac{\mathrm{d} \hat{J}}{\mathrm{d} m} \right|_{m = m_0} \chi
    - \varepsilon \left. \frac{\mathrm{d}}{\mathrm{d} m} \left( \frac{\mathrm{d} \hat{J}}{\mathrm{d} m} \chi \right) \right|_{m = m_0} \zeta
    \right| = {\cal O} \left( \varepsilon^2 \right).
\end{equation*}
In such a test the first order derivative information is computed using a first
order tangent-linear calculation, and the second order derivative information
is computed using either a second order tangent-linear calculation (if using
the \texttt{taylor\_test\_tlm} function) or a second order adjoint calculation
(if using the \texttt{taylor\_test\_tlm\_adjoint} function).

The \texttt{taylor\_test\_tlm} function has interface
\begin{lstlisting}
def taylor_test_tlm(forward, M, tlm_order, seed=1.0e-2, dMs=None, size=5,
                    manager=None):
\end{lstlisting}
with arguments
\begin{itemize}
  \item \texttt{tlm\_order}, a positive integer, the order of tangent-linear
    model to test.
  \item \texttt{dMs}, a sequence whose elements are functions or sequences of
    functions, defining the tangent-linear directions (in \texttt{dMs[:-1]})
    and perturbation direction (in \texttt{dMs[-1]}).
  \item \texttt{manager}, defaulting to the currently active equation manager.
    A new equation manager is generated using the \texttt{manager.new} method.
\end{itemize}
Other arguments are as for the \texttt{taylor\_test} function.
\texttt{taylor\_test\_tlm} computes the Taylor remainder associated with the
(\texttt{tlm\_order - 1})th derivative of the functional, contracted against
(\texttt{tlm\_order - 1}) directions, and corrects this using the
(\texttt{tlm\_order})th order derivative in the perturbation direction,
evaluated using a (\texttt{tlm\_order})th order tangent-linear calculation.

The \texttt{taylor\_test\_tlm\_adjoint} function has interface
\begin{lstlisting}
def taylor_test_tlm_adjoint(forward, M, adjoint_order, seed=1.0e-2, dMs=None,
                            size=5, manager=None):
\end{lstlisting}
with arguments
\begin{itemize}
  \item \texttt{adjoint\_order}, a positive integer, the order of adjoint model
    to test.
  \item \texttt{manager}, defaulting to the currently active equation manager.
    A new equation manager is generated using the \texttt{manager.new} method.
\end{itemize}
Other arguments are as for the \texttt{taylor\_test} function.
\texttt{taylor\_test\_tlm\_adjoint} computes the Taylor remainder associated
with the (\texttt{adjoint\_order - 1})th derivative of the functional,
contracted against (\texttt{adjoint\_order - 1}) directions, and corrects this
using the (\texttt{adjoint\_order})th order derivative evaluated using an
(\texttt{adjoint\_order})th order adjoint calculation.

If \texttt{dMs} is not supplied then all tangent-linear contraction directions
and the perturbation direction used by the \texttt{taylor\_test\_tlm} and
\texttt{taylor\_test\_tlm\_adjoint} functions are constructed with degrees of
freedom taking uniform random values in $\left[ 0, 1 \right)$ (generated using
the NumPy \texttt{numpy.random.random} function).

When called the \texttt{taylor\_test\_tlm} and
\texttt{taylor\_test\_tlm\_adjoint} functions display the magnitudes of the
changes of the functional derivative value for each perturbed control, and the
implied orders of convergence between subsequent pairs of these, first for the
case where the highest order derivative information (at order
\texttt{tlm\_order}/\texttt{adjoint\_order}) is not used, and then for the case
where the highest order derivative information is used. The function returns
the minimum order of convergence computed in the latter case, where the highest
order derivative information is used.

In a valid verification, for sufficiently small perturbation magnitude the
order of convergence when the highest order derivative information is not used
should be approximately one, and the order of convergence when the highest
order derivative information is used should be approximately two. Numerical
roundoff issues, or encountering a special case where derivatives are zero, may
prevent these asymptotic convergence orders from being observable.

\section{Checkpointing}\label{sect:checkpointing}

\subsection{Configuration}\label{sect:configure_checkpointing}

Storage, checkpointing, and rerunning is configured using the
\texttt{configure\_checkpointing} function
\begin{lstlisting}
configure_checkpointing(cp_method, cp_parameters)
\end{lstlisting}
which should be called prior to solving forward equations. \texttt{cp\_method}
controls the checkpointing method, and selects between ``none'', ``memory'',
``periodic\_disk'', and ``multistage''. \texttt{cp\_parameters} is a dictionary
of parameters controlling the detailed checkpointing configuration options. In
more advanced usage \texttt{cp\_method} may be a callable, used to construct
a \texttt{CheckpointSchedule} defining a schedule.

\subsubsection{``memory'' method}\label{sect:configure_checkpointing_memory}

All dependencies of all equations are fully stored in memory. The default
method. Keys for \texttt{cp\_parameters} for this method are
\begin{itemize}
  \item \texttt{drop\_references}, a logical, default false. If true then weak
    references to \texttt{Equation} objects are kept by the
    \texttt{EquationManager}, and their \texttt{drop\_reference} methods will
    be called when the \texttt{Equation} objects are destroyed. If false then
    strong references to \texttt{Equation} objects are kept by the
    \texttt{EquationManager}.
\end{itemize}

When using this method checkpoint data are \emph{retained} during an adjoint
calculation, permitting multiple calls to \texttt{compute\_gradient} for a
single run of a forward model.

\subsubsection{``periodic\_disk'' method}

Checkpoints are stored to disk at regular intervals. Keys for
\texttt{cp\_parameters} for this method are
\begin{itemize}
  \item \texttt{path}, a string, directory in which checkpoint data should be
    stored (default ``checkpoints\textasciitilde'').
  \item \texttt{format}, one of ``pickle'' or ``hdf5'' (default ``hdf5''). The
    data storage format. If ``pickle'' is used then the data are stored using
    the Python \texttt{pickle} module. If ``hdf5'' is used then the data are
    stored using the HDF5 format \citep{hdf52021} using the \texttt{h5py}
    library.
  \item \texttt{period}, positive integer, the interval (in blocks -- see
    section \ref{sect:blocks}) between disk checkpoints.
\end{itemize}

When using this method checkpoint data are \emph{retained} during an adjoint
calculation, permitting multiple calls to \texttt{compute\_gradient} for a
single run of a forward model.

\subsubsection{``multistage'' method}

Checkpoints are stored using the binomial checkpointing approach of
\citet{griewank2000} (following the maximal trajectory of their Fig. 4), with
multistage offline checkpointing using the allocation strategy described in
\citet{stumm2009} (with a brute-force approach used to determine the
allocation). Keys for \texttt{cp\_parameters} for this method are
\begin{itemize}
  \item \texttt{path}, as for the ``periodic\_disk'' method.
  \item \texttt{format}, as for the ``periodic\_disk'' method.
  \item \texttt{blocks}, positive integer, the total number of blocks (see
    section \ref{sect:blocks}).
  \item \texttt{snaps\_in\_ram}, non-negative integer, the number of
    checkpoints to store in memory (default $0$).
  \item \texttt{snaps\_on\_disk}, non-negative integer, the number of
    checkpoints to store on disk (default $0$).
\end{itemize}
The method name, and the latter three keys for \texttt{cp\_parameters}, are
based upon the configuration of multistage checkpointing in dolfin-adjoint
2017.1.0.

When using this method checkpoint data are \emph{deleted} during an adjoint
calculation, permitting only a single call to \texttt{compute\_gradient} for a
single run of a forward model.

\subsection{Blocks}\label{sect:blocks}

The ``periodic\_disk'' and ``multistage'' checkpointing methods each rely on
the concept of forward model ``blocks''. These are sets of equations whose
solution depends only upon control parameters, the solutions of other equations
in the block, and the solutions of other equations in preceding blocks. The
forward model blocks may, for example, correspond to the timesteps in a time
dependent forward model.

During the solution of forward equations, the start of a new block is indicated
using the \texttt{new\_block} function
\begin{lstlisting}
new_block()
\end{lstlisting}

The ``multistage'' method requires the number of blocks to be defined prior to
solving forward equations. If \texttt{new\_block} is subsequently called too
many times (i.e. attempts to define more blocks than are defined in the
checkpointing configuration) then the surplus calls are ignored.

\section{Caching}\label{sect:caching}

Many numerical models repeatedly solve the same equations multiple times. For
example it is common for a time-dependent numerical model to solve equations
repeatedly, once for each timestep of the model. If an equation is solved
multiple times then optimizations can be applied, with data cached for reuse in
the later solution of the same equation \citep{maddison2014}.

\subsection{\texttt{EquationSolver} caching}\label{sect:EquationSolver_caching}

The \texttt{EquationSolver} class (see section \ref{sect:EquationSolver}) can
implement a number of caching optimizations automatically. Specifically
\begin{itemize}
  \item If Jacobian caching is autodetected, the equation is linear, and the
    forward Jacobian matrix does not depend on any non-cached objects, or if
    Jacobian caching is unconditionally enabled through the
    \texttt{cache\_jacobian} option, then the forward Jacobian matrix and
    associated linear solver are cached. 
  \item If adjoint Jacobian caching is autodetected and the adjoint Jacobian
    matrix does not depend on any non-cached objects, or if adjoint Jacobian
    caching is unconditionally enabled through the
    \texttt{cache\_adjoint\_jacobian} option, then the adjoint Jacobian matrix
    and associated linear solver are cached.
  \item If the \texttt{cache\_rhs\_assembly} option is enabled and the equation
    is linear, then right-hand-side terms in the forward equation which do not
    depend on non-cached objects are cached. If a right-hand-side term in the
    forward equation can be represented as the action of a matrix which does
    not depend on any non-cached objects, then assembly of the term is
    converted to a matrix action, with the matrix cached.
  \item If the \texttt{cache\_rhs\_assembly} option is enabled, then for
    adjoint Jacobian derivative actions (see section
    \ref{sect:adjoint_derivative_action}) which can be represented as the
    action of a matrix which does not depend on any non-cached objects,
    assembly of the term is converted to a matrix action, with the matrix
    cached.
\end{itemize}

\subsection{Controlling caching}\label{sect:static}

As described in \citet{maddison2014}, caching can be facilitated by declaring
data which are known to be ``static''. Caching of \texttt{Function},
\texttt{Constant}, and \texttt{DirichletBC} may be enabled with additional
constructor arguments (see section \ref{sect:flags}). All other
\texttt{ufl.classes.Coefficient} objects are assumed non-cachable.

\subsection{Clearing caches}\label{sect:clear_caches}

Caches may be cleared via
\begin{lstlisting}
clear_caches()
\end{lstlisting}
Cached data associated with one or more functions may be cleared via
\begin{lstlisting}
clear_caches(F_0, F_1, [...])
\end{lstlisting}

The clearing of caches is automatically detected by \texttt{EquationSolver}
objects, and existing \texttt{EquationSolver} objects do not need to be
regenerated.

\section{Object flags}\label{sect:flags}

\subsection{\texttt{Function}}\label{sect:Function_flags}

\texttt{Function} objects may be supplied with optional arguments on
instantiation, e.g.
\begin{lstlisting}
F = Function(space, static=static, cache=cache, checkpoint=checkpoint)
\end{lstlisting}
where the additional arguments are optional logicals
\begin{itemize}
  \item \texttt{static}, default false. If true, declares the \texttt{Function}
    to be static for the duration of the calculation.
  \item \texttt{cache}, default \texttt{static}. If true, results of
    calculations using the \texttt{Function} may be cached.
  \item \texttt{checkpoint}, default \texttt{not static}. If false then the
    \texttt{EquationManager} will keep a strong reference to the
    \texttt{Function}, and it will not be considered when applying
    checkpointing strategies. \texttt{Function} objects with
    \texttt{checkpoint=False} may not appear as the solution of any
    \texttt{Equation}, and a \texttt{TangentLinearMap} (see section
    \ref{sect:tangent_linear}) will return \texttt{None} when supplied with a
    non-checkpointed function.
\end{itemize}

With the FEniCS or Firedrake backends, a \texttt{ZeroFunction} may be used in
place of a \texttt{Function} whose value is zero throughout a calculation. A
\texttt{ZeroFunction} can be instantiated via
\begin{lstlisting}
F = ZeroFunction(space, name=name)
\end{lstlisting}

\subsection{\texttt{Constant}}

With the FEniCS or Firedrake backends, \texttt{Constant} objects may be
supplied with optional arguments on instantiation, e.g.
\begin{lstlisting}
F = Constant(1.0, static=static, cache=cache, checkpoint=checkpoint)
\end{lstlisting}
where the additional arguments are optional logicals, and are as for the
\texttt{Function} constructor.

With the FEniCS or Firedrake backends, a \texttt{ZeroConstant} may be used in
place of a \texttt{Constant} whose value is zero throughout a calculation. A
\texttt{ZeroConstant} can be instantiated via
\begin{lstlisting}
c = ZeroConstant(shape=shape, name=name, comm=comm)
\end{lstlisting}
where the shape is specified by the optional \texttt{shape} argument.

\subsection{\texttt{DirichletBC}}

With the FEniCS or Firedrake backends, \texttt{DirichletBC} objects may be
supplied with optional arguments on instantiation, e.g.
\begin{lstlisting}
bc = DirichletBC(space, 0.0, "on_boundary", static=static, cache=cache)
\end{lstlisting}
where the additional arguments are optional logicals
\begin{itemize}
  \item \texttt{static}, default autodetected. If true, declares the
    \texttt{DirichletBC} to be static for the duration of the calculation.
  \item \texttt{cache}, default \texttt{static}. If true, results of
    calculations using the \texttt{DirichletBC} may be cached. Note that
    \texttt{tlm\_adjoint} currently cannot handle the case where the values of
    a cached \texttt{DirichletBC} are modified after their use in an
    \texttt{Equation}.
\end{itemize}

With the FEniCS or Firedrake backends, a homogeneous Dirichlet boundary
condition is defined using e.g.
\begin{lstlisting}
hbc = HomogeneousDirichletBC(space, "on_boundary")
\end{lstlisting}

\section{\texttt{EquationManager} objects}\label{sect:EquationManager}

Internally, when the \texttt{solve} method of an \texttt{Equation} is called,
the equation is processed by an internal \texttt{EquationManager}.

\subsection{The active \texttt{EquationManager}}\label{sect:active_EquationManager}

The currently active \texttt{EquationManager} can be accessed using the
\texttt{manager} function. A new \texttt{EquationManager} can be created using
the \texttt{new} method of an \texttt{EquationManager}. In the following
\begin{lstlisting}
current_manager = manager()
new_manager = current_manager.new()
\end{lstlisting}
\texttt{new\_manager} is a new \texttt{EquationManager}, with no equations
processed and no tangent-linear models defined, and shares the checkpointing
configuration of \texttt{current\_manager}.

The active \texttt{EquationManager} can be set using
\texttt{set\_manager}
\begin{lstlisting}
set_manager(new_manager)
\end{lstlisting}

\subsection{Interacting with an \texttt{EquationManager}}\label{sect:EquationManager_control}

There are a number of functions which can be used to call methods of the
currently active \texttt{EquationManager}. In the following the
\texttt{manager} argument is optional, and defaults to the currently active
\texttt{EquationManager}.
\begin{lstlisting}
def configure_checkpointing(cp_method, cp_parameters, manager=None):
\end{lstlisting}
Calls \texttt{EquationManager.configure\_checkpointing}. See section
\ref{sect:configure_checkpointing}.
\begin{lstlisting}
def manager_info(info=print, manager=None):
\end{lstlisting}
Calls \texttt{EquationManager.info}. Displays information about the currently
active equation manager, using the function \texttt{info} to display strings.
\begin{lstlisting}
def reset_manager(cp_method=None, cp_parameters=None, manager=None):
\end{lstlisting}
Calls \texttt{EquationManager.reset}. Resets the \texttt{EquationManager}, and
optionally defines a new checkpointing configuration.
\begin{lstlisting}
def start_manager(*, annotate=True, tlm=True, manager=None):
\end{lstlisting}
Calls \texttt{EquationManager.start}. Enables the \texttt{EquationManager}. If
\texttt{annotation} is true then enables recording of solved equations. If
\texttt{tlm} is true then enables derivation and solution of tangent-linear
equations.
\begin{lstlisting}
def stop_manager(*, annotate=True, tlm=True, manager=None):
\end{lstlisting}
Calls \texttt{EquationManager.stop}. Disables the \texttt{EquationManager}. If
\texttt{annotation} is true then disables recording of solved equations. If
\texttt{tlm} is true then disables derivation and solution of tangent-linear
equations.
\begin{lstlisting}
def configure_tlm(*args, annotate=None, tlm=True, manager=None):
\end{lstlisting}
Calls \texttt{EquationManager.configure\_tlm}. Configures the derivation and
solution of tangent-linear equations (see section \ref{sect:higher_order}).
\texttt{annotate=False} can be used to disable recording of tangent-linear
equations by the equation manager. \texttt{tlm=False} can be used to disable
the automated derivation and solution of tangent-linear equations.
\begin{lstlisting}
def function_tlm(x, *args, manager=None):
\end{lstlisting}
Calls \texttt{EquationManager.function\_tlm}. Accesses a tangent-linear
variable.
\begin{lstlisting}
def compute_gradient(Js, M, callback=None, prune_forward=True,
                     prune_adjoint=True, prune_replay=True,
                     cache_adjoint_degree=None, adj_ics=None, manager=None):
\end{lstlisting}
Calls \texttt{EquationManager.compute\_gradient}. Computes a forward model
constrained derivative (see sections \ref{sect:first_order_adjoint} and
\ref{sect:higher_order_adjoint}). \texttt{prune\_forward} and
\texttt{prune\_adjoint} control pruning of the transpose dependency graph via
forward and reverse traversal respectively. \texttt{prune\_replay} controls
pruning of the dependency graph during rerunning of the forward.
\texttt{cache\_adjoint\_degree} controls the caching and reuse of adjoint
solutions between different adjoint models, with caching applied for adjoint
models of the given degree and lower. By default caching is applied for all
degrees. The optional \texttt{adj\_ics} is a map, or a sequence of maps, from
forward functions or function IDs to adjoint initial conditions. The optional
\texttt{callback} argument takes the form
\begin{lstlisting}
def callback(J_i, n, i, eq, adj_X)
\end{lstlisting}
where \texttt{adj\_X} is \texttt{None}, a function, or a sequence of functions,
corresponding to the adjoint solution for the equation \texttt{eq}, which is
equation \texttt{i} in block \texttt{n} for the \texttt{J\_i}th
\texttt{Functional}.
\begin{lstlisting}
def new_block(manager=None):
\end{lstlisting}
Calls \texttt{EquationManager.new\_block}. Indicates the start of a new block
of equations (see section \ref{sect:blocks}).

\subsection{\texttt{EquationManager} state}\label{sect:EquationManager_state}

\subsubsection{Annotation state}

The annotation state of an \texttt{EquationManager} controls the annotation of
equations -- that is, this controls the recording of which equations are
solved. The recorded information is later used in adjoint calculations.

Recording of equations can be enabled and disabled using the
\texttt{start\_manager} and \texttt{stop\_manager} functions  -- see section
\ref{sect:EquationManager_control}.

\subsubsection{Tangent-linear state}

The tangent-linear state of an \texttt{EquationManager} controls the derivation
and solution of tangent-linear equations.

Derivation and solution of tangent-linear equations can be enabled and disabled
using the \texttt{start\_manager} and \texttt{stop\_manager} functions  -- see
section \ref{sect:EquationManager_control}.

\section{\texttt{timestepping}}

The \texttt{timestepping} module defines a syntax which is similar to that
defined by the \texttt{timestepping} library \citep[see][]{maddison2014}. For
example, the diffusion equation example described in section
\ref{sect:diffusion} may be implemented via
\begin{lstlisting}
from firedrake import *
from tlm_adjoint.firedrake import *
from tlm_adjoint.timestepping import *
stop_manager()

t_N = 100
configure_checkpointing("multistage", {"blocks": t_N, "snaps_in_ram": 5})

mesh = UnitSquareMesh(100, 100)
X = SpatialCoordinate(mesh)
space = FunctionSpace(mesh, "Lagrange", 1)
test, trial = TestFunction(space), TrialFunction(space)

psi_0 = Function(space, name="psi_0", static=True)
psi_0.interpolate(
    exp(X[0] * X[1]) * sin(2.0 * pi * X[0]) * sin(5.0 * pi * X[1])
    + sin(pi * X[0]) * sin(2.0 * pi * X[1]))

kappa = Constant(0.001, static=True)
dt = Constant(0.2, static=True)
bc = HomogeneousDirichletBC(space, "on_boundary")
levels = TimeLevels(levels=[n, n + 1], cycle_map={n: n + 1})


def forward(psi_0, psi_n_file=None):
    clear_caches()

    system = TimeSystem()
    psi = TimeFunction(levels, space, name="psi")

    class InteriorAssignment(Equation):
        def __init__(self, x, y):
            super().__init__(x, [x, y], nl_deps=[], ic=False, adj_ic=False)
            self._bc = DirichletBC(function_space(x), 0.0, "on_boundary")

        def forward_solve(self, x, deps=None):
            _, y = self.dependencies() if deps is None else deps
            function_assign(x, y)
            self._bc.apply(x)

        def adjoint_derivative_action(self, nl_deps, dep_index, adj_x):
            if dep_index == 0:
                return adj_x
            elif dep_index == 1:
                b = function_copy(adj_x)
                self._bc.apply(b)
                return (-1.0, b)
            else:
                raise IndexError("dep_index out of bounds")

        def adjoint_jacobian_solve(self, adj_x, nl_deps, b):
            return b

        def tangent_linear(self, M, dM, tlm_map):
            x, y = self.dependencies()
            tlm_y = get_tangent_linear(y, M, dM, tlm_map)
            if tlm_y is None:
                return ZeroAssignment(tlm_map[x])
            else:
                return InteriorAssignment(tlm_map[x], tlm_y)

    system.add_solve(InteriorAssignment(psi[0], psi_0))

    system.add_solve(inner(trial / dt, test) * dx
                     + inner(kappa * grad(trial), grad(test)) * dx
                     == inner(psi[n] / dt, test) * dx,
                     psi[n + 1], bc,
                     solver_parameters={"ksp_type": "preonly",
                                        "pc_type": "lu"})

    system.assemble()

    if psi_n_file is not None:
        psi_n_file.write(psi[n], time=0.0)

    for t_n in range(t_N):
        system.timestep()

        if psi_n_file is not None:
            psi_n_file.write(psi[n], time=(t_n + 1) * float(dt))
        if t_n < t_N - 1:
            new_block()

    system.finalize()

    J = Functional(name="J")
    J.assign(dot(psi[N] - Constant(1.0), psi[N] - Constant(1.0)) * dx)
    return J


start_manager()
J = forward(psi_0, psi_n_file=File("psi.pvd"))
stop_manager()

dJ = compute_gradient(J, psi_0)
\end{lstlisting}

\section{Applications}

\subsection{Functional minimization}\label{sect:minimization}

\subsubsection{SciPy}

The \texttt{minimize\_scipy} function can be used for functional minimization
using the \texttt{scipy.optimize.minimize} function supplied with SciPy
\citep{virtanen2020}. This has the interface
\begin{lstlisting}
def minimize_scipy(forward, M0, *, manager=None, **kwargs):
\end{lstlisting}
with arguments
\begin{itemize}
  \item \texttt{forward}, a callable, which takes as input one or more
    functions defining the control and its value, and which returns the
    \texttt{Functional} to be minimized.
  \item \texttt{manager}, an optional \texttt{EquationManager}. If not supplied
    then the currently active \texttt{EquationManager} is used (see section
    \ref{sect:active_EquationManager}).
\end{itemize}
Remaining keyword arguments are passed directly to the
\texttt{scipy.optimize.minimize} function -- see
\url{https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html}.

\texttt{minimize\_scipy} returns a tuple
\begin{lstlisting}
M, return_value = minimize_scipy([...])
\end{lstlisting}
where \texttt{M} is the result of the minimization, and \texttt{return\_value}
is the return value of \texttt{scipy.optimize.minimize}.

Note that \texttt{minimize\_scipy} does not raise an error if the minimization
fails -- instead you should check \texttt{return\_value.success} -- see
\url{https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.OptimizeResult.html}.

When used in parallel \texttt{scipy.optimize.minimize} is called separately on
each process, with global communication used to gather the degrees of freedom
for the control.

\subsection{Hessian eigendecomposition}

\subsubsection{SLEPc}

The \texttt{eigendecompose} function can be used for the matrix-free solution
of eigenproblems -- e.g. for the eigendecomposition of the Hessian with a real
control space -- using SLEPc via slepc4py
\citep{hernandez2005,dalcin2011,slepc-user-3.15}. This seeks eigenvalues $\mu$
and associated eigenvectors $v$ where
\begin{equation*}
  A v = \mu B v.
\end{equation*}
This has the interface
\begin{lstlisting}
def eigendecompose(space, A_action, *, B_action=None, space_type="primal",
                   action_type="dual", N_eigenvalues=None, solver_type=None,
                   problem_type=None, which=None, tolerance=1.0e-12,
                   configure=None):
\end{lstlisting}
with arguments
\begin{itemize}
  \item \texttt{space}, a function space. Eigenvector discrete function space.
  \item \texttt{A\_action}, a callable which accepts a single input function,
    and computes the action of the matrix $A$. The result must be returned as a
    function.
  \item \texttt{B\_action}, a callable which accepts a single input function,
    and computes the action of the matrix $B$. The result must be returned as a
    function. If not provided then $B$ is considered an identity matrix. Should
    be supplied if \texttt{action\_type} equals ``dual'' or
    ``conjugate\_dual''.
  \item \texttt{space\_type}, ``primal'', ``conjugate'', ``dual'', or
    ``conjugate\_dual'', defining the space type for eigenvectors.
  \item \texttt{action\_type}, ``primal'', ``dual'', or ``conjugate\_dual'',
    whether a matrix action is in the same space as the eigenvectors, or the
    associated dual or conjugate dual space.
  \item \texttt{N\_eigenvalues}, requested number of eigenvalues to find,
    passed as the \texttt{nev} argument to \texttt{slepc4py.EPS.setDimensions}.
    If not provided then performs a full spectrum eigendecomposition.
  \item \texttt{solver\_type}. Sets the SLEPc solver type, passed to
    \texttt{slepc4py.EPS.setType}.
  \item \texttt{problem\_type}, the eigendecomposition problem type, passed to
    \texttt{slepc4py.EPS.setProblemType}. If not provided then
    \texttt{slepc4py.EPS.ProblemType.GNHEP} is used if \texttt{B\_action} is
    provided, and \texttt{slepc4py.EPS.ProblemType.NHEP} is used otherwise.
  \item \texttt{which}, which eigenvalues to find, passed to
    \texttt{slepc4py.EPS.setWhichEigenpairs}. If not provided then
    \texttt{slepc4py.EPS.Which.LARGEST\_MAGNITUDE} is used.
  \item \texttt{tolerance}, solver tolerance. Passed as the \texttt{tol}
   argument to \texttt{slepc4py.EPS.setTolerances}.
  \item \texttt{configure}, a callable. If provided the \texttt{EPS} is passed
    as a single argument to this function, after all preceding configuration
    options have been applied. Can be used for detailed configuration.
\end{itemize}

Returns a tuple \texttt{(lam, V)} where \texttt{lam} is a NumPy vector of
eigenvalues. For Hermitian eigendecomposition problems or with complex PETSc
\texttt{V} is a tuple of function objects containing corresponding
eigenvectors. Otherwise \texttt{V} is a tuple of two tuples of function
objects, the first corresponding to real components of eigenvectors, and the
second to imaginary components.

The \texttt{action\_fn} method of \texttt{Hessian} objects (see section
\ref{sect:Hessian}) returns a callable suitable for use as the
\texttt{A\_action} argument of this function. The \texttt{action\_fn} method is
used via
\begin{lstlisting}
A_action = ddJ.action_fn(m)
\end{lstlisting}
where \texttt{m} is a function defining the control. Note that the return
value from \texttt{A\_action} is a Hessian action (\emph{not} the complex
conjugate of a Hessian action).

\section{Copyright and acknowledgements}

For copyright information and acknowledgements see the
\texttt{ACKNOWLEDGEMENTS} file in the \texttt{tlm\_adjoint} root directory. For
authors see the \texttt{AUTHORS} file in the \texttt{tlm\_adjoint} root
directory.

\bibliographystyle{apalike}
\bibliography{bibliography}

\end{document}
